{"filename": "ncnn-20241226-8-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20241226-8", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "1931280", "isize": "8975086", "md5sum": "dabdb3f24ac8f127975e6c2ec3f44abb", "sha256sum": "3b3802185a601889287ce1087553d8681d0edc76756423228ef34a6d1b334404", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmgzWpUACgkQdxk/FSvb5qZ95BAAqAos6WitL4T6vimTny8My3X9glQ+OzKFnnc2nfRG7YXTRhFdHqsbq2Mb+STIIVR19EjQJ00bzgTWL4e0vT3zVO8mz7uoh+flreLY+ZXd0YJxHuJr0CxATVVC2BBxc5g+rKcSokyR1SbPWIExvQ/Pe0yIpvSYLCHp1k7L15+iJpy6zSoWqZ44NuEvAErX/6z+Wd7QkXLdhiwVwJMsUZRuy1i2jKm+xpiyrWhkL4bqtUBtMONkskAAe2YMi75A6UVw0WjSP3jfbkGXW3Baechv0K8Ozs8KZfZDzPwklzRWw5Gr7wNEhgeLmLO64PSjvKyA5HqmnNBXiDfeI0OR7yQxkZ1+Ux3VKqkefdlSVJnH1t4t3i/ngg5rTBuRyhfarvTm/TmqnqxJc3zs7aq02iWmVuvnfx4LoTILXvsOU6k4MQQ9r3s1ANBLEGVQldZ42fMNxvpcYi6Cu4ZdLNSpqESgfiglEDwwST9dcl/cZVHq5stchU+RRB+NH3acx9kTnlUXXts4Akq54UguLnn26Y9PG8jtJxOoJ9F4yStrMGP2nvSGKhrnfGor3HFESkJ5FVlC/wbeChgjC7CnNgOIFAf0eMw0sufhBcT5nQXVGJvJXFX7fGvZMMYuns2HNdL2+Pjr9BzvX39jI3xhU94jMyt441vyN1C0i2Thz7ADGLJnYTk=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1748195819", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>"}