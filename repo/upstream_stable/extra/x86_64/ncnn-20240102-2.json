{"filename": "ncnn-20240102-2-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240102-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2868560", "isize": "12123924", "md5sum": "dea7914c11c49a91b0e08ebc86755c64", "sha256sum": "ad602940cd593265791e5816144718dbb1c86c0db9ebce8d914b81b7e14b137c", "pgpsig": "iQIzBAABCAAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmX1wA0ACgkQk7EdqkwZfj3HiRAAzXtgIKzimLIF2HHnGJ5Rb26bH5FhMA0rpGmEabApbvgPV2azL0zdQ/p5b8eGoagVFMJQQiMcZv0H3f3VVrmZ4cQ37WoA0mW+Aakz044ZB4XW4FRbf9qWx55DV6JPjbkZED4I1zPjgVpVVgFazjZ1wfnbLpN9Ee0UMjYe9+tt/+8nkyX06Q+BLJMY9oJKDBblS3nQaT3+MxKIY65Js6GQSp6aPJlYFsKoMlewaFjDij01jtYV/EM5kcQS3MNhuccRhfdRGWatJzlSmA9nVlB9gCaXbyC3g1vAfIxNuVZ0r4avSu4mBI53rW2QThFPhLbqsZ7CCYr4/t5Z8isYCrwnf1g9SnY/vgaSyQUH54tSzNC656rZIAqEyyLW2AlrWQA7lN5+RE4kEqL4+rwC7Qc4Ye0+dOnRlETBBBrWtk/3N8YgXDcyS430FPLm2juY7+ZKzbOnNJyvXXSnYqOP1ZbRbAD7jj9piEM8BvoLxR4Z2zXIzWhwJjcShNSF44bywDtaU1TClKET5lgyGwdPUOaYPx7KeWYvQSxy6Kl9Z8bZ2cOfqp1y4xpo1LhzQyIW8qE8vAstOVn2Drbvqsw/XbPJo1go3b3i7s8qPXk0mYm8YdydwBqF7Jr6c7Hf6gsWHJVEYPIuPJGvafwk+ZG/xeRfJipf7FAgCKP6JNZYwtPBSks=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1710604218", "packager": "Christian Heusel <gromit@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}