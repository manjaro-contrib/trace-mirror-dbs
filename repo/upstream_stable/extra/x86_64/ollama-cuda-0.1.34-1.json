{"filename": "ollama-cuda-0.1.34-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.34-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "428192673", "isize": "447560605", "sha256sum": "6d549909a75adb8e692d4aa43b3bb52e94cc267e4ec782b8e72ea5e1c957a4db", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmY8pVAACgkQwyIX9vE/8ZLyIA/6A92hPhg/uUuLGrgIlV/O7iXfrbhhQbCXgNJCbwidjWMWNBJTaWCVRKcQVMCMzE0wVUGbzfd4IYN4mYdmYmU6UgK72m/JZPjO0isq7A6R0iQp6nx0DNf4yo9uebHqJTlksdZ1neo57e3puhn/rywHJLs4G+4tu/izIB1zmBd/HbGCZaELBS6tkJGKGINfzdg0d2ej8eK1CbD+bLbwd/3EK74yraXPSdJrzmJ4rFGHEq2RHZgoJtEMBwQTl8u8/ZIcNmfBcRB/uKiLWpmyeQTOw+B0owD0HGCTBTHdB4WZE/Owc1QCUlceI3a2qki7J/ki8zFAx/+/D7ze4dQD5pL863Zu9oGrX48AweV9miO0qB5DXcEADAabqVAFdSHlMj9s43mrCM8BO368ra82okTjevlgF0hafWSmS+px5Tc5Nkw3YNUo+X0fn/jnNQqgBI579F/csi7Y0EgRt1NDgrvCcAWqqJWdE6nnPduHozHeuooRa7ShbOEdSWioBV+wk2hH4bXojJK+I8TWFjrIOq5j+WIgo+VsDw+/zf8JtGrlccSaFcGgR+AP19Fx0+VijK7mcGH87QAY4Z6lzYBoZC+H+VoYbPI7HWSfdkpKe58uvovUzaRcBWCVAdjW3AGhnEUdHsG5MrZdz4xhkkb2l7hK/8s9jfkLjeaJHlcYzAPChr4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1715241191", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}