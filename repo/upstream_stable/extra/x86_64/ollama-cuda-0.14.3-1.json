{"filename": "ollama-cuda-0.14.3-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.14.3-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "228386872", "isize": "1827740936", "sha256sum": "c28312ea4be26492b4610d7f5565675562f0256cbdda69ab7ff2eb2461cd5e17", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmlxtLgACgkQOeS4d+YuuRVmHQ/+OnOL0lNyirmM7KLuesp+OzMz4LI6YMxwJMSwMima4amfKyB87ICDxEk8OJ0gK+i16XqPcuaSzeRXMeFrGjXkxFR3smDn91R6qyW1eyPUCtYJHCmaBFwdyXhEueIvASUWy6btHAfiZ4lzIRawzr8d7k1BvsNLeXznrrd/I2JSUgfMwRVhMlumdA21YugG+tW+yWrfXpJd/+ZTQa66XZzwdwN5n8dLdwLmO0v9egwk5lYoNyFJTqep0mNW/O8cd1jwQgdy9RuSkmXOKBq5+aUXmHIKPYfsGVBWmX1D4MOnycCQcnZEl64mwixJCrdbRUeKmS61FNJ4T21/0+KObM05bEMt68ZE+rsdkYmrPhWYNVWdXzTSZtEWzcKIRIVj9RnOnN2M+VNLhGHjXVhuY07LuGdktnxQiB0meXzYeE4Z1o3WQmj+1M0jK87lORPXY4DumIsu5P5kGKt6vUofulbZTXThOniramFUxV/nElToWJaqaKcJ+QCbbqBAb3x5rHgfTcY2NBheVlD8CULVq10uREjp8s9hMGJBJhGSwdZB3u3DiQavepK6rCEDM6OMjUMa4OtHK6WQldIbgRuufTErwmRACpLbEhuiqN0hhXUk9ff3V9leliJpdWav5zERFAgmuBBetRU+rEJZzdjb4q0Kpo/QIo+jGVL5xwd1PmQQD1Q=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1769051417", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}