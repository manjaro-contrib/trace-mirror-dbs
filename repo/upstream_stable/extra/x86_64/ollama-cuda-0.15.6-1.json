{"filename": "ollama-cuda-0.15.6-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.15.6-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "231027328", "isize": "1850440896", "sha256sum": "01a3ba2701ddf0fdc8c584026804420aff88b926e39a1bcfdf92da328264b0fd", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmmMeUUACgkQOeS4d+YuuRUQRg/8C2jB9yioXHIfKdfQUbeKqh/RHzs33IbNGvQMOioo+ALiBNzM1DkKjuHHLcXiEk8Gg3V/Vqch6B1X6PjW4xaWHQcDKEJ0PKrEomnyM7XcAdSN5CL5g3guQTnmPFEiJh+613nDkKqXQ2j1Thny28uc9iLGffax4s9+SnDeETa2wRLl4OMmbMeMIQVwIu7GxOP5X1FQkQr8pVeu/M6NEzikFo1qObI0c2kqrnV6koSOTXGwGKnQQLZYpgvZy34NEvqLDanFVq/FgIpC21nfLXwU/C37HesPWKaA2M3RzHGC5tVIhStGfDSpNzoZOkVjGJHjRTqOHwarGJuu4OLlnApX1LQxe4hvhd+Q70dDmh2+ybR007m/pdzMWVDAnO6UriHZH0ELwZJCceTWM1RU8Xm0e6i/XS6tI5TX4oStrcSN7/rRTjBbH5GyxWfz1ltmOuz+LM8285VaRvePdldVTI70lM7PArN6x9lM12Jy/pVuyrC8K3mPFQQk1YZt3kMLRN+vj7P0mksv6cDyvbRTA7N73isIwzJleIldgrBXa9hjssSsbFAGL8mbmHRu50UZWux2MglalyHWQArq+Yy5iHSPxrMqK5diuz8r0HMc+SOKWbcIJzP0PxRvYJznacvrr9BfVZYJTCWBYrvOW+HHfMNIFLS10gUfI9Wku1x5ONivKZc=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1770812490", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}