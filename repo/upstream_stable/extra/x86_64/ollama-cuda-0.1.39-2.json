{"filename": "ollama-cuda-0.1.39-2-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.39-2", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "447774529", "isize": "467528469", "sha256sum": "7bf7140d05716a68457e06b62e96693399366adb5b0b9c6830e30f4192ca08a9", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZZbesACgkQwyIX9vE/8ZLjSw/9HDe6N8/u05GSkE5Z333ZB1IxiPbmRrhTQqOrqbIp5sm6U8KveOY8BCIEgbro+/eDE9ixU7BVzyyvAXBSMXRuPzU+SXxzjXZAlYSF4xjmjqzqJzcEm0kVfb5/CC2M6hte5/CMnhvwf1n8WAmaqbZfUJRCKzznuRY5OTJE5kmtg+f4U6jsHoJdGaRGdnzRqJkw3vGuNR4djQ4kZGJecEpK3VBu7EB+2Oq6NW+V8BNFdGU3YuMcJsqYoBPx11H8YgwADW94bp1q2Lk5bzA67utWmdxj6B22QIdzbVZbQgcV2Erb6vlXYZ44Tjg70W22gWn+lURD8dG3lPUd1kfZifttUIsw2jSlh0WvyGxRoftJhsvaYl/VYTJD0RYW2NJbeEQNzyRRpaw6IAxeCVaNpV5yg93Af5j2YCAsCN7RotyM9bhaM+ipQNpwUHtYxUdn1g99JaSfm0PGtfMadVdDIEYYoneJKF+y3OW1buc3zjcxFjMm1BFMwcO4cT8NmUozhrxWw5g3X67Hobi52AgpRIA0A+bV6AHAVIx3lVLOMWAUGfFDilNsUhEpVDhjsZQh/bTQRObrqs02q6eQOqijkpsDOVUmv9K8s6TCns90mJcXe59cEY1aE6jQCB8Ev7AUeP9TajgcJjuesfyTFCjH0cKkp54f1CCdawgUf88j3BCP7DA=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1717111502", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}