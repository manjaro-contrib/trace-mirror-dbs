{"filename": "ollama-cuda-0.16.3-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.16.3-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "230236272", "isize": "1850518720", "sha256sum": "78d65c646958c218026687280db26900529e01e9e20ecc87651a9eafb53b7dd3", "pgpsig": "iQIzBAABCgAdFiEELjbYYgIhSC/EXLfyqRdkdZMmtEAFAmmYbdkACgkQqRdkdZMmtEC37A/+KcNvZsG0I2M91yyyq+z2gjm/IyVnwhaK1UxiiLoRQUi9s8ragFZtro5H7JQLZQSinzNA18Zcr4iZsRmNqWNNgLxAgKpNmbcWz1S8O7k5G9magSqk7wDyU6XIRFCztb8NiOasd8Dnpc4VJZXARU2xPYz/0Fsi2DBbRqdQMKWgu7z2QcW0ucY4an+cIwkL7zvC4lZ3o/JpP2NdLoWUgqhbXX6+ktDs7gdqD/fWWZIovJfZF8X0iWvm2Wj2x8pQC/EzUjPaXc/KYx/KeWnPw6vOpB8Ba4B5jTt3lHyGd4jq1dfx5kvO8+5hLBk7p7vKaOtwVKlpMb0yE9zMF03Nq8Gt6HQ6bWCYnc1aSFb/tAThU1jaQH1S1x1Uwfr426wPAcjh6QTDv/tEwgE27wgVJq/ZJt8ACQFiEXVI05TyVx+oXAURZq0G8yoQbE0oftKt2ZRUpkMfj4ONWp0usTGgJafqh3F9XGozb5XLKYdBrWaCp5wSUW4TXQImUo5rq7LGypjaKjOkuWJpMQpxWohXtJHQ8EPfkcu352AdsDXC87ofS/3fiLCY0U2WBNlrFB9739ccdAKS5bwCc5VkbYYS3dEZtktzG8zDlqyd5jwWvxkyzgRsHuWkDCUk2w4eKt6G9s00iEJJIq1evFwryS0iCI7ep62K60w4QPHCnaVNM8UZyhQ=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1771593649", "packager": "Lukas Fleischer <lfleischer@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}