{"filename": "ollama-cuda-0.1.41-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.41-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "447958654", "isize": "467905301", "sha256sum": "efd8b610063e3aad71aaa2cf4eb9fbfcc01a9fcbc965e58b55d1152ce7e9b1a3", "pgpsig": "iQIzBAABCgAdFiEELjbYYgIhSC/EXLfyqRdkdZMmtEAFAmZcn+MACgkQqRdkdZMmtEB0QQ//Z+/3d8+mejy4dz2C31YFeX9CDw+wfstC9g6dPUMPWvhmNqWyKWjC+zZoPawT9ReVpsrJUm7sb2LysbdpOL5EheZqZJna2NdYpKfagngfF9H9xS0A1TdBIY0MBzq5Xv3cxV1prmJznNhnFUeNSm+Iftg+ZEcZd9bKm8GcEgkd6dSn/QLvJh/cIFO7gDTP0HeaoWZ0/iIUzzfp5GeI0oCmgRxVDzwIL9S8jCnTOaBcVTK53Kjb62wRpP/xAXELNXFsMRAMEDMNPa7Un/NplXQ5Veio9LC4Q3nK0P9VZzyP4UuyM9LjkwYJ5XDunlP0kaPOi+sD1P1+dbasS+LgBrIn9ROjMqv0/UyFig6n6s4B4FP745adBphn875mVwmyDkf1Exg0+fNZEvP/uCnbbz+tCiiFMkj0/nFNMRPPHhhboM+c9u6vQjW2VTL8uCX0ujdEEGYy8gojIYsNoK6qrgA/lESGoABJeJXEC0cNJTJ0tnMw7dfYMNrqmgTcMJDIr2/XZcjDcW9P2iyClJYNM6l32/OUbVzSh96T9tGsuTWQHiTHuJxtAYDG+ZaxAqqrSkb9KZvWjvbmJw5Pd4dXxAUQjHgpem5yxeINMfJ6bVB9RNIOYP1evdOEiesXYr8cmAmO/sAVE9318WbdGjDurCOdDsmQv+Ascx99/U5t+ltY2HE=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1717343505", "packager": "Lukas Fleischer <lfleischer@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}