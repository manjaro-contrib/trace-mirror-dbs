{"filename": "ollama-cuda-0.3.12-5-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama-cuda", "version": "0.3.12-5", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266672216", "isize": "292184959", "sha256sum": "1f6c4ee33f5f2a8c30f8485fee70493592b29f065db9f72f15189bd347d0ee82", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmcvsKEACgkQwyIX9vE/8ZLHRxAAw29KKOfllPtWOGJ8QeZxopmOfM+9cTAfCVSo/Pt4LwvjTD6j/HXxS6/pa8w52PmPlvUi/F0dl+I32BfOmxQmkQy2jtjTvc+D9f0dlTXmWa9etoYId6av1JSKHDfrRawMJd1EalVIcHZJn/xNRAwYbLMycMlXIbBuRt7+YnfBAPMvS/I2PoQXWUpQrXRo8RTv8upKE6lkcUoA9Px0gTa9hWXoimzaPtkBRg+GcVAZhjQzMqIFQfNgxUI3uVTol7h31bevkXZusLO1BlVdHRNtbrRRWo24/y5jubU5gh5v+TG79DKRRm5nPMwb7G00cNUuDCXiE3aBrygA5uHssH3HXNsQg2g21H43gKWPvnfG4SknOu8+iUaiNSgjbwdeh+WZqK01MekNSUDCHKacY64wcKhrmqb0RWbaiSpDU/Lt8SBmk4gZoPwihnGffbbHWPhd4aApigNMb+TMTS+xRIyQXi11Q5Ix/0jOxlRo0bkhwZ+fpQmc2TymjhMr37ginPbMGwwcOnnmceoZFGrixVIujvBNJZ58sBKzvSXyl7HRWir9g2dTe3f1RAZwVHFFF5SLj6zdUHgshcsZsMUgPBXgzhoWMbYkfFCpj5e6+KBsqrGvEE12w/7yYziYDHe9byimuaknkbbipHO4HHJn9mhX/jRKPCHqUzWPycg94AnF22c=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1731174514", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go"]}