{"filename": "ollama-cuda-0.3.12-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.12-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266546887", "isize": "292183881", "sha256sum": "4f7d820e2f7bcd70890b311a64418ee97d4572ede55248b30cc4be3b6795c713", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmb23HwACgkQwyIX9vE/8ZIvlhAAnCrc61D+JGIesViAfo4WmYZJnruHbMGaTI5eunpdbbk/mRWIafOcnkf5nmFafXxKYisjodgLdRXTLC811RQE5tydJuxG236IdwwjOQjG2C8DIcQV2pkH5jxpkCjwlz+sh/p5Xbalv3XJiWBUajctEy6ZT4NmN72/SsFF5CUJd7QtO9Te6o/jyRnVqCyGJZu6T8dJhymfdDuWf6RfSwnN6DepZZGvKTZmITyZ/jTWHkAkN7FEOWBzpuDnp59BZOTeVl27LiJ9oyrLOEjKtVH8VE3Q+mz9/NxyqBBsJERkrWFvgE48kqGgbnJ2/zqzROqwPU72lq+tzU/yRM6FwKi3dbubIwOg23cidRiH4Bf41kd2Ml4Mda49a+NItzVyRsAasb60WI4gLundgwKVosejbfUEhZOXYG11JXGpWZCjndetsp7F4aEVZLW/5bv3oM80FYhpbn76VUodlRXD4p9CagW6kyv1tEovcS0UfSCETts1/yCXl47x27yYIXQAOQqvA+5SfpUfNDlromcFn3Yl1WP+DLMOgJjoUXjwXhqE1BtWVwKNbh2Qb+URrK7vCxXhbiNcercU5BH7ZTx6LJ9mm/mFgSEezkKnPMhCAoMptQz+/edaaJhUXcjhRPQHNt8iy/rj5iUFj+cqK3IWvDKhoX7fNztXhfDW5+c7kxLWC5k=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1727422938", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}