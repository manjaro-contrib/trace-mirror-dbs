{"filename": "ollama-cuda-0.1.44-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.44-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "448026272", "isize": "467919938", "sha256sum": "04a9a0dcffb38bf02af50806cfb29aa6003e8e317ee32594d9ef86f46deeee98", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZssNQACgkQwyIX9vE/8ZISERAA0KVVJlWhUSgf/MaKoYqswMXY9QlBfVNrZTBB1+C5IPifWYhWKtrPDQfSUSo6W486ud2mH1nXLwIYe8EG14PzRj0HQ5Vs0/+1KEYSXMcmr//pEzXvtVLuim5mbyhUsIQXMzmwmoOaOrmlzsS4MTu5Q2jVi7BkJCzLJR4Nj0+UCrj9oDNATAijHAKsIWFfDTQaPRv6CDGAOAFNbHKYRMRobVD4Ph2WzpQdlkyNVvcUpyiwhxTG8KOnjjz1usCVbBhOYtzU36TMuPqIcw2+iCw3eRUO/dbxZiPyi4CGX6TCPnNLPEmm3w7TsofOXj8keuKOkC3VsFTPMau8NljodwRh27gCbBUR1N/Fg/FmpbCICAG8XxG46G3qEQ7cpbmrV4ePh7P/i27rTrha680w7SONE/M9uylSPxTX++32zohWSC8iDTm9+foL/SIF8bnly5m9mJoM+MsOGB37Wn07ZeTu13rTiPFRuy8ZOFGqT9Y2QVfop0PGUdbhhtUiCt5c1aUzSS79gcE3FcVQJR4/rji58g+R7WqEOPNIYkVxuyPjHz7ZbyLbHaSrxGYRJn5qjNZsgYRJ0WWxbIKKsFK1FgL2nvRGv9BwaMa2Ek8kNiyi+jVhR8k7bQ24KGRhTsDdvH/uhX6W6+hVPkVaCWy24x3JULgAx1p88ouicL0K1DJjpNA=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1718376127", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}