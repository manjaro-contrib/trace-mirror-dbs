{"filename": "ollama-rocm-0.3.9-1-x86_64.pkg.tar.zst", "name": "ollama-rocm", "base": "ollama", "version": "0.3.9-1", "desc": "Create, run and share large language models (LLMs) with ROCm", "csize": "190844487", "isize": "211059618", "sha256sum": "5abb8e182cd85a4e032b2fdf80c1a1721a7a3bc31eab54a032c3445c2d350dbf", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbX/O0ACgkQwyIX9vE/8ZKXnxAAgISTz+BlLpyVZr/kFHu1w55+igJ6Mi9DkF5P5psCBFRm8QbdnhLzc3T4iygUTnJ3TZZt9JMj/xMJV5/Vg3nOZb5JlMS9evq+eJ6kyMaeKamiIBUzQRMcro7Vova0fd1XXqx2x0o7v6liiXLTEN6elUdXnrgwv6c9z7+53JW1LcjfTUlGQnSd0/S0FKUiS/srEzs14Dk2MbEIZXVRuHSPfDZb9JQ3CiyXiM2eX6W4Ca1h9FOoCAvolEK42QTKPY5Q4TlY4Z80pNXAF0nJF1pw9qEgxbV23Do+u6etgVVbZJ5v/6TOn4fIauNxozMp4VZ/oO3p2YC8VTlDOdUDLYkTtPlL3LrBsaOm616zmylXYBwmllvepfqC/y1hjmc1yR96vOT1IuU2AUiGNPT2BUZ2cR4/M8YxI2zH4dk0HvRnFHrgKVwMG5d3JutiYnXQx4JwcNEHt8FNKXshdKBuYW8M0VwyvaRI6YWLVtfYSVsFGaSpwbdJMyTllvcVRqiWunbjiH4LJwzCTkLprzZeg2+mJVCVlBXRHMAxnbARVDbDYz2/MNxJt6NJrgRniw/fBjvzvgf5BouGO4OCdUzpPaSzujSbS7wOMM99OBboGbMqWDzeewhqOsidCWcNss8S7doS2U/b+yX3xKureyxK+Le22V9CM7UVn8V1v3b7ufz3tpk=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1725399707", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "depends": ["hipblas"], "optdepends": "rocm-smi-lib: monitor GPU usage with rocm-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "parallel", "rocm-hip-sdk", "rocm-opencl-sdk"]}