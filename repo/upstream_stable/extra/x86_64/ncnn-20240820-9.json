{"filename": "ncnn-20240820-9-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240820-9", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2931926", "isize": "11987046", "sha256sum": "bef7a04423a54a50ec3eda1e70c8df766faad9adde93e81d998dc901c60fa184", "pgpsig": "iQIzBAABCAAdFiEEJipY7GxR9+o5Wy4t/cMEC5Ksp0gFAmdkOnkACgkQ/cMEC5Ksp0jVHRAApkDHZJXMJHJnh156LfJRpgLqhreuDiqdQY2QSArUm84TozFvHxHxMRA8TtUVinDG3OY92uGjaXP4MgZfpZo4z2Tj0yZTQAVtIkxKx19gZZiC5C6p34YjBpV8W+ablWh+f8fHLnOnQqAdkldbG/Ata6xguL3hAWPCzSEqKFPjfirDvPvLZ8s+23F3DL4k0rbgzogXlDJb0yG7frTVTQuZXfc9+qUB5vlc+dL/Y/kXI3iqg4w2xZV+IeHQDD2sjWQUbXnUpKDPLvAEF7qhChoxi40EuYlGqYELRFiQ/iO2L1Xydf/p0cUk3Xt6sQ6jFOOYSrJGOGMDLuX+GPvceGZYRxhxwwsL+d/iPwWu+q8yrMk6M06Ytb7TVhcyke35Cis0p7mRtt9Er82Iha/1Sf8Km1f273gjOm5RzzyADU6Oul/Br+GRoE6v3JUymVB5ME3hy9hSbqV5supFTIUIx9fbKUcBrfsnJYMkcijgZPdcSp2Ok5m6wg0os8uXpzBbjef/6fWbc9IkbtFoZEHuj5pmk3xd/kogay2Oh9RydsIwTS+0Wm2wyntmuFbIDYCDYwkYk4gg+dg4W38g3ntnje2FDoiz2u65Is6WFUpTQdGfmjKBxJGjvQC73N2DrEOL8/4HrJsDaVHKNriVVcqPVjiEd/nKIH8v6l7LOOiO7Um1PnU=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1734621730", "packager": "Robin Candau <antiz@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}