{"filename": "ollama-cuda-0.12.3-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.12.3-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "178269652", "isize": "1362409448", "sha256sum": "c7e93472dd614686887db25cd36d931544bf7d10ba5169c8a6d47d7b83707d50", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmjWgkYACgkQOeS4d+YuuRUF6RAArQ8kYVSHUYSZWrLkPq5jlXqBLGXVxSAD6OJuRoNZoVhzR/wu+othUS5c0/N3lBQt2VT3kxmxoAISvGAjgwDNf+guWT6+IYcgrAHwz8r9PGkn3aiMxiljor+MRMxngRnDibdsQwWQ7siRoO7WkqL1o+wN7VBdp211GScGhkaQpZnrQAPFQ9WKlrx8D94giCwuHuTVEkE0YYlUojFUzBkx+Lx6IpqXE/BPrmph00vZIHtTxpj+Ep4/5bmes7KyGahrJaT4OTCQgkA3xbevtSzsiY1G9xBqVQBPcbnTesQLu/YDnaIByiG3Zc7iZ6lfuDwJWm3QuTkuZBTa690Y108B45t/DISxm4iGI6r5cfdWqA9AUgw7fJUvErBrU8ytK6X4E9ZP9ioDGu1ePrPp6JJNNLoggjYVBPjLDwfeFDCTIN3cMF3D05UZQ0IylmQGzph8KgUGEBCrE52cil9u5jTczeWeTV4ZEkCdAOxh9E2YsrV9IJ9W0+P96VP9uhJEYWW9K5pMjDJBZdvVQjBmEJkkm3kK3CZCK94jiPgeL8/yJXuqiQfT/wiFVEtYvoK7akiApSrNIeCMpsrY34NxT/WVdzK1nCjVvm4n2W3v7r3HL3/Tr5eCVEKixDQbIpbVosqKYUj0SNXQtGNv3OHs3OKPzqttSeOjmjx3GttWZt0kP/Y=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1758887090", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast"]}