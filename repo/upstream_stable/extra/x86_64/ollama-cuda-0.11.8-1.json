{"filename": "ollama-cuda-0.11.8-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.11.8-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "152829335", "isize": "1405315080", "sha256sum": "6da09f91109f5311024ba154e8588574b51a2da70e4dafc2a479758c3eabc67d", "pgpsig": "iHUEABYKAB0WIQQEzwzW9u6TrhiW9YQH0GNRylsxvgUCaLGWugAKCRAH0GNRylsxvknnAP4upsK1KuNDKGh6JoPo5kYuxLPA40RSs1duyHQDZIYTDAEA4Hk33skqNfkY/KzgjBgSb9hUSFaC3It1A8W8mDcJswk=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1756467828", "packager": "Torsten Ke\u00dfler <tpkessler@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast"]}