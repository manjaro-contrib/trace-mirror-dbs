{"filename": "ncnn-20250916-5-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20250916-5", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2941942", "isize": "10392185", "sha256sum": "552ef3409bd06b0f699b64c107f1f8010a1aea0ac3891847153f012d97f78ed7", "pgpsig": "iQIzBAABCgAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmknJMgACgkQk7EdqkwZfj3psQ//aaYa/QdVROhfnDyWA/dcObqqGPck8eDd8zAuoANn6n9bRwrHSFNh7qcPEB9G2jOqvFUAX9eWQmz9bEL9NdLYyX65tz+ttty17zQWE0jYLJm2xqlq9HPFpFsKzMwli0fhPAh7wFuF0zGTXqTP8lXRAsie0CqDXLYRBb3EGmpjX1iJ1mud7t71obGLcx6yu1dO2uDYXzDp2Wz/PTBrC51Woy7YpSkaP3qykQ2OjsVELcC4w438quIho4WGolq1BC0ldxW8D8HgwUy3hd7v6Jsbs00fOoS/9JsmRstQYnQqTfxjOOVxkYCTVTtUMzenHO+NIl+RKvfgZW5lXUVVFBlW4DmWA8qtRVxKCMU3UZP2W1xtrnVIRY+J4AlHCG+iINwlQuwotDdEswsdS3cqVIuaSkAm0pe3fC1xhjWHAWN3deW1xy0/YVERwXSqSX1q1uUlqCspVFEFZu83ldOejzfprqlEyUtHwNkicQNB+SdMIVyil2S52IPZGOcoATu/xGM0YFIvOl+5BUUDypZ36EKo6w/CCdTA0jGpEzAfpO6PC4D1vlcaqfGSsLno+EmWkvoMeh4o8HbtNd990owXjzD9CduJLt7VMUtM26twEXA8pj9k3AcXnP0Ymzt7WDShOuxZ50eV4rnGSbRjUGstGDzr1YzC4wOCiOdGPB9giBTSP/4=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1764172906", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}