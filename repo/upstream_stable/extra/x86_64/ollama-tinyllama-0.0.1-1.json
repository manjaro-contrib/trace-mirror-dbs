{"filename": "ollama-tinyllama-0.0.1-1-any.pkg.tar.zst", "name": "ollama-tinyllama", "base": "ollama-tinyllama", "version": "0.0.1-1", "desc": "The tinyllama (1B) large language model (LLM), for Ollama", "csize": "605175266", "isize": "637700989", "sha256sum": "d581ff76be9a96068d8cbd6ff4ee169403c1c061e2fa1b76d47163c1996c72ea", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbYYsQACgkQwyIX9vE/8ZLhUhAA2aMWJ6THasp6Sys35+uglR85OtX0UPTiRsBnZix8NA+NpIAS6C43kJHzBGFgpDNDe7LgTU+WqMIBQRr1sQkih3GNJ/TDr3defCZvlhr9BSlhs1Ovydr60h43+c7MkIR1KtnsiEQLVQm1mRVVM/m+85obJ2ZEQKtux2hMekuo4WxOu7lRaP3clOftMyapQoYsF5dW/r5AjU15g+mt8Ew8vm5va2+y4ujszyhgov66pT4GrY0hg4C63GL2/R5vkCCciXKUPnjnP9H/zy5BVGV49+DzTCC2YwyD4GKhwLykBQzyx5aSGHqaV+efbZo+B1sNlUEEa0ioBD643O0LlqSNlgFMNxlZOoWZRcWiT5PfhYKjD+8qwzyn8fZOOIijHXQ38mTLySxo+0JOB26Z2/UAS3l9rKgp6w98NlBNfAgdX1QNbk8mVNZqF4isGxLrfotqcXalmuo8g9+zTJB0SymwuTUp7JgQaYsvb8jKPXGdgEAiw+MyuzdT1/PZbxNKkE2XB1kJYl8mKM4mf+X0BF+zO/gy+NlA60o7gdR0q2bKA1oq5e1/6aUMKkwb9lEHF6a9F5YEoKmRQ3Ve81MzR+aoSo09pg6xEFq6foJjgTy9VCudIdLsZooD3ifaihVKVjvScW80JXINNm4QfvTAz9kbONTw66whlQFRCaZaCULiViU=", "url": "https://github.com/jzhang38/TinyLlama", "license": "Apache-2.0", "arch": "any", "builddate": "1725456837", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "depends": ["ollama"], "optdepends": ["ollama-rocm: for using the GPU", "ollama-cuda: for using the GPU"], "makedepends": ["netcat", "python"]}