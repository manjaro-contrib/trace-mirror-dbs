{"filename": "ollama-cuda-0.1.42-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.42-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "448043122", "isize": "467928034", "sha256sum": "7c8d0e529c17e4c32b94a0d5da215c4d9dea37fca7d819cf4a44496890c734cc", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZk7y4ACgkQwyIX9vE/8ZKrEhAA1a7/oqvYbn3j5ouLansk5CuErbtasF3OjAbcWY4vZj7cgn7WMXVxde15GpHpytJghKC5axyT/AzsiQ5WqPY6y3jCzcTE/WWOnUXNUgSPrgCrGfQKCTho91wwIkfAeSPggTCCHvv1VqNDoJgDvZygEvJZgnUnIJxx36/FmPRqVhzRdaRyh1RDmPt75zFf1ZEp2JQtNq1mzL9CfReZt40hfMPaSD6YgjGMJxeFQh5Y9NCS822B1vVSZ5a+v5/PiwmAplot4RN4pc1fVLXc8Nh6qiH3GDZf+CfPNYZ7Y4x3RSNuJN0xr2rmyDu49DMVxUC3hlllgQEQuN9U7f94hJffTLUiQTcK4pWnQGPu5bfTr5WbA3xGyuldyRojgE9A/N7S/06Kqs+uPMrClXyapDRYtZvEzTXAIQXvnb4VX9tLd3rc7Ms16abtjrY/eRVrdjiSsjt0XkUGc1TyFKp4yOwY7yf6aKmxR3+u67EfZb4p7T0wvKiAwl4l3uwEy8xHQSJafl1VCGzMgE7faf9xfzqwW4MAbDH72GLb1CmPRo+vJ1DN0TOpf6zmcO2g0fgueEAV3CO0FMvLY050PhnZ61QoY6HIai0T9VJJItVmqKr/Y/h4ukIOEJQ349Rl4FnuVKHcyg4d0IffHil2iHbfSjOlamNBP7Xz8xcghvzijynnJ9I=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1717887046", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}