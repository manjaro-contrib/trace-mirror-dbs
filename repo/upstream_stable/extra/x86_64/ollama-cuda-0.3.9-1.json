{"filename": "ollama-cuda-0.3.9-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.9-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "235142489", "isize": "260005642", "sha256sum": "9b981b527c23fa697aa317b77cea6275cadb2c3036224b6620ecf0e2ad875e52", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbX/OcACgkQwyIX9vE/8ZKG4g/+JICaD1CoDPQ1qYsaBj5u1oBYIr6f1JABhkj/JJ4kk8D8y+Yo40QL6NvSBm4zMVrAnLX7R0xG3KOD92NWWPA8bA+Bq/lwCmI0SqvXLPypXcSlXZYJ1oFjMjTf1DHl81rAz1+XoDo38sA1lUQ6g2/FuPiK4eirvR8lPe/SN5xr3P3KK9sSI0VyLV5zfTmnbfXjFgga3tx+Eh54UcCwi5ZClSYjQa91kFTgX5MvGgwg8YTDMCikeDE+kivFiJVh2ajU9J/7j2PHhDSG3ImMpRzcg2ymUYVqMDAtbqXBBi46XQccv6XHJcu3CZjoKfr/98k27Lh83D2ZOXLA73nBKyqlNTZAzMvieRo6hxxdUoDE+0QojpxBC8VY5q+zoz7OaekEsP4PfNezaA02h59cCnYyEPel4vwHawBefgNMSwqSB+7kG0zk/oSIh6wN+hq0/8EY4iA2SNhhLeOsABokKyizwzBa04rBSCI9KmPe5UYF0Zw6VivgTWyCZOTBJfzUJA8bsdhwwgvH8R5ycaNHVhfraKla0TxGxg5CNUoM2dk6XGVPs8GlMZAFhNYpcThxUgRxdMrw3U0BRXR630wg8Xm6vDtnK7t4egyZHHSluQ9zNdzplTM1dy0rbI78ihi1MByw4zWQgzuPa1bvGK3N+2BgCjiKe6R/4uKfNF8SAo8keD4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1725399707", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "parallel", "rocm-hip-sdk", "rocm-opencl-sdk"]}