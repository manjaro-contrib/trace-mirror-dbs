{"filename": "ncnn-20260113-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20260113-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2870583", "isize": "10202771", "sha256sum": "6ab865e96908173a47269afba5fcfda0a8b2e72477544959607cf00be04872c8", "pgpsig": "iQIzBAABCgAdFiEExdKm4O0tEcZrn6KjBjE5EQV91agFAmlrY6YACgkQBjE5EQV91aiB/RAAgwmKB3k5kyzjaX8s0YrZzLk5nxtq/JUm13ZkK0IlOqvZb5kbPRx9C9PYZZBTFzVmnmPr7HvOecwzTUuyfwQOdeeNYvAEbdtfi0D8ESoSzWK9lHqGzXNaYz6Wi0a2hF5PUrYDAgf5v8MMgGFz5Sh8OoU1CjxPkjyjkECuRc1v+m+9Z0bj+EpIddabrB7/BMV6vqkdyVjOzUk+MlSk5dUMghnK92d4qfb6BwLU7x5iZF8G709nzPYH6fOVzGv3mboh+8zWcMCd0J8S3WNuN5ssEIsjK2bxR5OFR1W2or/tN//Rh4vkbXFOMi5UKRn/rwiKRJQBfSpbkUpNfzmsVyljz3IvUEnPYq7Sj6b6ATLNNGb4jD/aHQk0AZ2OOyqi5uIPCoQ9zPGxHiG+dr2ynb5q89dSuEqOyAMAvqlC5lvPjDc6TWITVfEIIhKMrRtybnLZdhPwwlxBpO8y4B9p9+xR7/KY8p+Pqe8CVKxh2W2h3Y1iv4+DDqjKgSLnYrrUpuXcyfwPFDL7zpVsopwULbP5x189VMR+mFuTVluUhp5X1636MCbBXdl5CiCI4Pmgt2/Vs9u/6U9In+Hp2+qBoQw3pUVPTUOmrX93fzBDeTfK43T4hwma59jmtAjYaqvs3vRYR+ZDgXzHG1/iHNWfcg2WQzdxgotYlQlbVFthCorGY+w=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1768645300", "packager": "George Hu <integral@archlinux.org>", "depends": ["gcc-libs", "glibc", "vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for caffe2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}