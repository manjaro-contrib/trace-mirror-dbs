{"filename": "ncnn-20240410-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240410-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2762184", "isize": "11363131", "sha256sum": "ceaae4c0cd0ad53fedbeb04e5d9b46398ff09a5ffbbca53a3fbe6a6c3b4d0c31", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmaY3SQACgkQeGxj8zDXy5KSZBAAk0yQSv+97KnU5KMK79TbAWuhSHANA8yVhTtneb0oHhTwUNVTQ9OfCWp1ZIBajuwRii1380xdPoBPQcg4FEQ0PWDI8zXX594N9WdwmT4+6ksV7e2Edj3mQc+AFemdCLDw4sssUIBe+cK3YRiVKVKMhe+TlXv/nPWLTr7JGziTeSU4n4u2g5qvek3g2Wf3AW9DKjaBcRP2o2u93upzWMo1PBLnM6MmXzTMnDhWPP0SX31bHesr7cVlpJGU0lhgIA6zqrzp46CoKpknN0hJR/kHkEFcVcUBixmvPy+5OB82sq4YBi4d825xFDky9XTU5fKbPoeZP49dlZHdZrCGyeyQjC1HzmdROIP0mUsEltye4PhBFbpXQsdPgnT0htIanp9xtsOjtJetgTqaGyf48dUnu3XeeqVET0VZxJjSv4LvD1B9K+iLt/60cOFHGkpiaSdcygoku9clUL8yWlide67mjYJbKXC64V+fV1iFLjEqAzZXcSgrGag4Ll/5Z0Fj1KQiB52xoQ+mpoD7AF4Y3mMAUVBLpl8CB6idhK8ejdC7JCw2dwZ31bXoBkSzImNKHc6Jef0mnCO06rHE5LeAy88lNDfodtpK/4tA8YQYzQDTL95AXRYPcyYyDEITUjuyE6SYOtUvYtw3z0j1sTaVj28JGfjxodYvkZoqFeqwZBD0VlE=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1721293981", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}