{"filename": "ollama-cuda-0.3.6-2-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.6-2", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "596350195", "isize": "619092746", "sha256sum": "291242cb443c41d6c9b5e189035aee9352fd2ab1f231405409314549d8d2d3b1", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbDeVwACgkQwyIX9vE/8ZKbrxAAq0Le9ARDJuiNvUh6osLjHmdp3cJNcTJ+pzztofmzQcltdGoVl75kjuVQhNZCWBYp483/y+7FQgV1rYl+0Kkna2WVOR+zGKRBAPIiyouYRDkyQUa3/eOHk8pWBhatyFaZ7lo65hcbW4jvB1dn10OyLcKcm/2reS+celwCokH9smqesRMx0OID0gYsstgi7iEqJvsTU8jqdokGuT7Cea8CrYLEFYCuzLy12Rki0fS0FNa/kK/8vqEjkhZ6mQoF2QbSvgSf838aKiEnVR2FQew9s/TRl1B8hGR4w9SKlbfXbUyusjx8Oj/CeeGv/fgIpZOg8onPdaIfeD71uUuBahnZJiDBrial02arTEpW+hpW4YcSUsJsr/yobmEBox5j1bdR0sCXE1NzE90Rg0CIA2fD3CBG/7apnptLm+kVFkDwOdDD9VMBF/SzKZUfLPE/qJ8HLC3aHKJZG40ryESvdb2zmCho29JIjNcvFOkddgXzlN45HTqmrdrP+QEGzZFo3WJ+mxIC2CWNm1WYNWT26MdBM11vgkZK3ONpi+4y1e2ZkM0luDk6Bi5/T7U0xwmTQx3cu7u1znY6XfFxEc4qAZ+6+obokB/hWPSalwqcrs1p+z5BYMNFczGeTbI0Jmq8is5GHoi/Nr/5LU64eAVRm0iy+07smnlhadpGgVEoNO0wgUw=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1724071415", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}