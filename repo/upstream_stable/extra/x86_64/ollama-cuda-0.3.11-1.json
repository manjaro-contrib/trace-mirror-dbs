{"filename": "ollama-cuda-0.3.11-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.11-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266657271", "isize": "292183881", "sha256sum": "b01d0bef1017885c2445ef561c097d1a9445d2bf5f17f3beb43e78e8b51e35ee", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbwUnUACgkQwyIX9vE/8ZL3mRAAqoLNCI6weqlgGH0eUyNvtmT7C0ogjPm7qBjc0ffZJaEi5PUOCh2iA73jGqDf0himHCQJB7ZN5awtc7u2QfsRf4lhALscxVSrdetT1UKdLJj34ldopW0MzfX60TRnQXIrTub2ue4zrTwGj6yLGNCX5d8+lfTQXfr7AM+UHqcBrFMPkknQivzuFIno7jlvWArod2+OzfMtPHTeNjHNT2NVcOScTdnF17+6LzDsnN6JP4xpDiae0d4rbdwEGDjxQhMPaJqd62tk9LTwUs3pvwrOa23nHoJuSAWVNNUJEQKt0VksFBDPitu7Bwl4Yirjie9/iVmRFuezsfrnqvOSp6yDx57QAq6ovzCUckB4H0DX0Aw7Fnx5sSuxDpVef4YNPs/LKo0i+pjqNdY9/tJgc3uOYhbMkUSsreP2SmLb5hfb3aYkhqrB9c5qE7RHBnug5dgveqTZ/X/sc/IfF4B4GLSIY+3dtcyP1CmJgZwdGrvJRhojtWo0i0iEPjeeSC7yB15f8wMySMQwpp7mwnRKD9vp9rbP3AIhDjpGQD9EsolDD0uudViSExcvlhHcfNQokQM5IIBJXWcTHQllmwF2zAIj3PWhijUKz02nfttQw7V34s7odQzp1zNzUwLcKVmGb9ictSzAPw+MiwK5ilwgQ33xlIenT4m7nPfz0JQvoKAZ1+I=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1727001857", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}