{"filename": "ollama-cuda-0.2.5-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.2.5-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "549573114", "isize": "571230210", "sha256sum": "43560ac484bacfc5f0c4669d9d20ac0a045976dcc575ace24dd85fd400e140ba", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmaVJGgACgkQwyIX9vE/8ZJGMRAAmSKmDQr8XMnaEodjzxkgMg9D4A8Ue7ZThLmPOAh8vmkyCSi9TQtjccI2wgiLadHzT5+X7lqmhN9kR6VemRaSZz+PpMfe9EKGByNsHesPZ7Ua+XTKQ5KmvVpxWqtwkxJDdqzMOERdGAJ+rhvRJgQ5xQrOvZa1ykcsunSy+QmncIUul3LAxUdMJk1J5v6RN9k8J6IITBkJfxVpSe+vu43SI1E5aGoaxshL4LoS8fSGmn+eLbDHnIofgaKOlqRR1aBWVz/9K59hXKW2/KPCyRK+8uz/XMSeZNk3/vLALEn0XzVtgtq7Wd7X7pNKYUdNKjvALQRH1kUdk1B3FkjsymoEya0Cyg0e0MQd9FjwZrDfSAKeKOp3n3LP6KHeL85dIFeDF2MYoQTJrSLdyhSVfj6TfpMrh+a513u1DI5b7s/WxThW5Kqim/RqyRhlcW7TcWZXWmScEVwX2rL95S3UjhAvGNU3gIVUnjxLdUAni7npPGCft0Shc4LffWRCYrpkyldWUb5KbSFxW7bNRCUBu3kZem6/+Ys9c6myW7RXLZm3zT5/vU5dDXSMHqGXe0UwLUIWHK4oQ6sBcMX0OJo0F5kxZYNgjvYz0yaI+5rp+2fi8MJM9N2Si1kTFwWQMyUqqqQOU02sVajeAd8sUOUklwqq8LHJBYVMyrCHfPawGnn7Qyc=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1721035592", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}