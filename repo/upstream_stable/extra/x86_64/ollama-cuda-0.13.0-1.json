{"filename": "ollama-cuda-0.13.0-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.13.0-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "193589569", "isize": "1633363904", "sha256sum": "2b9f9ef481904d8a732a96690804e2694833ee48a4a8dd985159b73a1f24b127", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmkiA8wACgkQOeS4d+YuuRVYtg//QVehCc3KRp8Y4A0paR2GQGHtXYuwcJtRmJfttpikSec/HRnxJygT0iA5Uf0j1oONrMHysAST937oRvW4MYHw0glQhx4/QRapqQe47uQzY5y9Z0ehOw83Fv686Y9ZV8ARMnASIgI3Mi3sjqKWwvkJ1wN0gQaDdAsaNldJ+oLjZpIwG9udAw1hPvijSYRCaGD/l/YRrkOfdt55DtCd/b+6Ld88SBofiMppAthNQNUdDv8GgMAcM8CIr4+A0mKxodhISY6t76jHL73P6U5PKAci6ICQ2sGoY2WzbTag4kcvxcgP5JfMLVYZXZIULopORmsWM04S/a/4Fr+/0BepyFrjHwn941xYG4NyrtuK3Dp6sXnQyLMhZM/9vsVKKdq/6DXSBD25IQMN0KI8Iy9GBFgSPn8e+sQt6Gimf3Rsdtw+DYPXTn7g6PhTI+VwjKKXnM1/xCH4pCq4Bqfxzx3sFg37i1kWDYG8852MoMhdnKn6zSpVSsQ3hG2TMuAZYZ7Cew+07ML//fUtVoSwxJvkMDsnRtpzJe+rVf5/R7iba8ts1VDh/T8KWs1XwROmkyTxpjNqcFKPUfWWDVYe5N5/PiOwjXQ0NoGesZKea6W0iVegVkUcRPTuBvnUCRxOSEdWUdK/4HjiuB5QFSNBm0wqaGc3m+J9gl+5HV4H//DrjNooaKU=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1763835285", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}