{"filename": "ollama-cuda-0.2.7-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.2.7-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "549430504", "isize": "571365538", "sha256sum": "c8d5b6ee90dcc7eacf9532ecc07a8a0b5f2633c95eedaf006a6a4cbe46830328", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmabtewACgkQwyIX9vE/8ZKQFhAA1mrDtrH3sMQqFWW5D7DTVYH/mYSOk5ixMFaZwgBeYEP+alyOpVAfU+dpkEgryISsfTQAWiYkV6XZoHqeK7oXgCOL79iGVajneMuEBSoPY57845no98BhrVRiWUaP7IEYkoRMR8xw0M6me0R23oo7gWxq0nI/IOBbSLmQuzJ4dpC5izsNNz6nwB3ZyhCH0Y5Fn9NDIy9SfXyvA+ChHblFTdM4pxclF+cSMDtEzFXbPUXptqm/cthVs9s45OMbRRQvr8gv0VjZD7pZBBigplhsonM9l/aTKZvmi8rNJm5EYkAaDp+6kKeMj/wJoCdR0ad6gbKabOeNZ0tVc/SCOQUgPB/Fr4c8dTDWVn6S1+cJOG29EBQTFqZlFXRfW9XJuQkPlGbXsfhXldc9d343KfMdc1vpygFphvrDjqnulQVCCfRg5NmcP9iHraW0XcoAOCm55wVxahZy+dVWcyWApdWRrCwWEL6OJ1nH8joH43xlxze8YvYT+IDTDJPCQoZ2Vn2MQEMwpXHdQDIuiI0wdUKAZaiP0D7L+5/G7QVP4u1LxSq8ZD7CZhUJopt4EksrBdf9KcpXoGb9Mp8hEMjEkF8hUAWr5f27EaDgL9vjy3qsmuu5OQAs1++5I4PjpBD5JPSb/gNoli3Hr9lY5JNv6dtKIb/3dg/McE74nkVVVnGySwc=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1721472613", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}