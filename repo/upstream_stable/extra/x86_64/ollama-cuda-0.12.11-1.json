{"filename": "ollama-cuda-0.12.11-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.12.11-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "193559204", "isize": "1633359808", "sha256sum": "6f5e6a1b62c9386d8a941f57a59c811c1c9ee16b4776ed4a5b5a97ca8160dd44", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmkWaXoACgkQOeS4d+YuuRWn/RAAscDyVJvW7JD34j1WhsA1d1+00OvHR2ZlAIqL1waAyEfgYdGMw6k1TsLl3VVRpVXB9+SzmBRFks4jIi2v4bFswUwvW40/4FuHsOFHiIiN5ASBVeU6t3XJ7yUWBR0bcZl8xawbsGOFeYrg0eRXqDXsEweR70LqELv90xXZNCy+tkWPvqYWUs+El2X7SUA8OiQ8E42fhiFP66TLeiymtiuRV3mbBDADFG8lTAWxhzRlPWs+6LhbA07go2O+hDvkQr6CBPgjmFDfatLWqXf276hM384wcbYTvyEYII/QIUSdutH/8QAdiqytm1SYVBcjoIRg/cAcTHgx3sbAmEUp3halLiBInE6HIeW+AIa3wCBPH8zg50os8Jy1maNE/uqrBHDrPw8xNt6SocQxKgHDt/FRdtwaHdxz3ni4lIiQT7QViIK5O2+elNywE3qqdQZhyOwT1x8Eunv+JMkgiFTzeQ0/2c81nOQf0/AuPteRNR0HpM9qwrYt9pY+tEsn52QaMfP4FInbjvS0kl6R0UqwjcB9d6b0H8Yob8FvBwkf5Iz/+7wbrDTm4epyTj63cVnvN97blmjsyFwHmwL9kPOq0s91YvsE2aV9J1NzT4VEE6jZQW/6H794lvhm4whh34giq/89KvmaxU8BWgRJsk9yzSORIzR8RvMWZ0M5CYOonD58Q8g=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1763074454", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}