{"filename": "ollama-cuda-0.3.12-6-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama-cuda", "version": "0.3.12-6", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "253631888", "isize": "292492159", "sha256sum": "59529df4287e4d46d89777ecd7962ac77c4d5cc1b79962cc067f2f83e5e65c05", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmdETEUACgkQwyIX9vE/8ZKE6BAAjACD42Pms01bMUvI/Y9jLJ27lShi4IkfendcqhFh01v6u+fOLhsVpIZx8/HdzPlPg0R7O45U/EyLPhRBiY327z4C5XJ0mTeDV76RMpwTDSaKHaNHgZiNMtp4Lryr+mCVnWSkxxsrFDVREBuMyom3KLqOp9UPe+PqHDCBxvaXCICM8cTY+UyRkGN2MJ5zNzlHz8s5pVPdXXLQTXV6Ut+WrwsWPMXVDnQw7kR8i7JipKO/x1MfgQInLBVoqCgkElvHxDBdOGq9GVp6rehQEj2SXQbtGdeCPwhJlMCKDnaFf1/RzpF0SRYp7QiWFzpomjes6wCyBYC1wdjH4KOjQ6GY4m7PSGEd41dAc5QuxdPUVzamJ5quG4Zy5a5gJGeMhE7nwlRj+WQs8OSbg9RMPYnfFHMmFI650aDogeJIQmjZsVgdjDI09IzhGdAj3DagLWrvGZBj3E36jtvkvH0ooFgJskS/6yhR8oQrJmsgcDwgXHmZzR4ryopY609rolvmF8ki8weCP2WAIsuNvITDFxEHZ054+o/NNbyBtSv0LU0kk6LGJLfe8iKUkM1QioDROLeAkP4YbbWQbmWio9NyygseJx68Vs/z5hFWQft4ob1ioAnrZhwO6EE+H3YTa5r/V19BVJXTcsKvb+pBqmF+Rk4K9u5E6hFvxihIuXFBOu0Caks=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1732525562", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "depends": ["cuda"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "git", "go", "pigz"]}