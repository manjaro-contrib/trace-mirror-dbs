{"filename": "ollama-cuda-0.3.12-2-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.12-2", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266248115", "isize": "292189055", "sha256sum": "d2fd4655f2566f81dadbb996328e88990e42d49d0fd9fcfbafdddb1d87c6ad8a", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmcbxMQACgkQwyIX9vE/8ZLQvBAAgl2HCvd+L4KUjYTXioeIAuo1jRw2jtrZxrwmKjRBUBWGYH6yQxx7ZdC6uRAgZ9uHu1gsc8tYAGtKGF8giS98PtrtzdqXwcK2999fsehq2Y/yussv/qv7KQPzthveJtU9zDYUmHjSC1TqdCfRKTnC4WGKeLkOeUU0/AgGoIqwkVFJl1w3x+WjA7QLdyJthwgFmtggiPzZq+bbJMsR7u3ekvstjjOPG7KXCsamI9aFp8Ca0M97bcpxJsbziBBGvRulPiFu/C5l3AQpjN6lbxsczggtaOZeduPZ0ARqJsNXmk1kOqWDctJUGVVVTFPCfVtUJFsf7p1b8RAOxVl7nKuFlWp0RKNXtJ3sPzDA/JhlRt8wQbWQf6eZYN/CjUiM9jbm1fdkr+68eOrDVa56RgbP3mCAYmQv7ABoysdKar5/iis0OiAEKh/kFwQDZm+pt1Zic/qUn/2RrJZpwnz7WlfFJ+txLvkTdrWuZLf/pARjhJ4siTlNLsWb4Z44bUb01VREEmSfZrrMw7NyMnTy4iMbUASPLsIy5MCq4ygAusGL20td/b/YGHMKWuKRSMTBMyLQmvvbdteSfbFdIS33gqSE+ObzjKlhK3u5H3UqY9/38Xr4lKJpky5+Lhh5dr7BdJvVCyM5Q3GFj6b0P4ar3g1qMpExLqNVhLA4DZESWcJqzIw=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1729857921", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}