{"filename": "ollama-cuda-0.13.1-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.13.1-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "193320249", "isize": "1633363904", "sha256sum": "d1c2ccbb6d059ca3af5087c5fece04f1593f5dd4050a6fb4b44d8cc605bd290d", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmkzi8EACgkQOeS4d+YuuRUcZBAAjzu9cWfd50Ehdm6PVYCKK2L1Hx2o3Pha3BCKwQTMLr/4vRUPs7whaRstmLWzUhgmcPUE6ven6k81wrH16Cl6dKWajVcWCTsTgi6Av8wD71dJIRcPb3g2yZQvgaSrMzVQVzhV3TBdXMgHd4Iz06Wbi+CNsO8C1ljllIIZytviysZdSerH75Q8vc5PPArWFofiF7xsx2YQCb36QLBdu2BWBEtu3RyqK92eVL8ix64j0hjbH0I7MzcYoGET+BGHc33aib0VV2QgY7fryzWNCFXj8XGwGmkVa1LXvxBIKQ26JOvMtnBlNZ6Ieio7WyJHXpSURrq2RpkDLaO9cqWVg7WxmbNUurrxNuE/hXkqPDOQPsTeeUQ4IQJaSPP2a70SxU3TkH5KUjAIf6GoWdPPztt+rjlcZ7dnn8u6KBLjzsT1okFDqPMhfTVkKpZQHgXQNceOD8QilGbU3T0KnyK7UaBDF8nI5spHnPiFYG5HQkMoe0wyBFv/vou+buxg9hDEbg9jT5XpBSfabOFFMEhdVVjwbKsFtSGvI/5zYWW/YSAxbLc2JxFNugrCtAzSLBmIuDmEKpjIPJJAKK34A+J5wFBqtK5KghxptqrZXnJZZFo+Z2KWtTWv00Z0bGqnRbtrFW0aeLOlyzZ7lCra7GnRSRyr8QmZHG0LFAXP2AaK5oiAeB4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1764984046", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}