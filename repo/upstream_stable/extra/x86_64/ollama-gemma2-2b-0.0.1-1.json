{"filename": "ollama-gemma2-2b-0.0.1-1-any.pkg.tar.zst", "name": "ollama-gemma2-2b", "base": "ollama-gemma2-2b", "version": "0.0.1-1", "desc": "The Gemma2 (2B) large language model (LLM), for Ollama", "csize": "1556061277", "isize": "1629527828", "sha256sum": "cbd588f30cfa33148686fc9b0485c8847c31d7ebbcf3bd9cdc464bdd5e34ca47", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbYdT0ACgkQwyIX9vE/8ZIWzxAAoJXDR0O/Bvwz5MvIfSh2GShA6aARQy0936/6YK+hIGbgcx9k0e0wz4MgddCKQ5gbpsm9of/0uzQEDWPAg+5Yq4tRmrmObhObNLm1VbitteTtuOfi2H7Iu01HEHM0LCicpt//HrUsNqhN25loK+lwcOh7ifnFPK5B1MHv4I/EhCO7wvGqfwpZ89oPu9IT/u72ofWFXuq0QrhATFqcRixslY3Pv9Vh7jeiPIf4TDBHytg5z3R6zoDLPs4BFMzdLCgj5LTBfnRusunSvDGyDTSmGpG/72xQC4gY+RCCVyhRRPaSRgqR3RUqsYMdatB8nBDqtpWZaqsCqKdim+HM8BvEgz+hCuXHPT9UclGotc7khn8OzgiKRiTAP4644OHM7n98ufOhYk2SofzZLKTT6geej41Fb5iQcOFTHgiLdqGB6RnR3oQDdTLAEJnaIR7yRh39Lf8Wc8h23wrpeV2gemqsVFeViNFqeci7V8txk7RcBDcq0ZW9g8zc8s0wFJ0mkt8gXl/eqxCCTgDG4fAx4NwAY7rYq5yL5XOhquGZVSjEwnxtMzKd/pblDHgZA4+tWJT69Cm5olCH3mQksWLyJ6UHN03Pafu9xSS1629m1ZYo82ar9GMbm20A9SVdw3ucUyl2zaKofFUE8KpoDmnRke5lM681QR/epjJYHtaNOSqyoK4=", "url": "https://www.kaggle.com/models/google/gemma-2", "license": "custom", "arch": "any", "builddate": "1725461137", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "depends": ["ollama"], "optdepends": ["ollama-rocm: for using the GPU", "ollama-cuda: for using the GPU"], "makedepends": ["python"]}