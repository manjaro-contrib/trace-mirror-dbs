{"filename": "ollama-cuda-0.2.8-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.2.8-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "596136338", "isize": "618449066", "sha256sum": "2d6205ff645ea1ffe635908da63645906645116cedc9d0d06f13d0655232d4ce", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmahLAEACgkQwyIX9vE/8ZLTghAAtft3nHMq0Yoq9DYnRcMeTypt7J1gmdUnzfkFnT9cBfmk6ryx9fVu091DuMhesSqqsMnThSACkf9I2qpC3nvEzJadK6xg3jkkB0VjhdwbXQo4LXiZVBYk79f8qQ4xVcxeIWMRCTleqNYRHgVDKKvlenbAPrTmHizZYSg5/YcWiu8PqChzXis6lhWrF1fz8Gm7Owt+k0/TXX/1OZ2kvKXWjCBBAjDHFPge1S9Yg3PRTCkekLo9kf8jrtXf9q/G+HlhIlJbX1MznZv4MARBq5YdCcABnaF+wle0wlavus0t3fe9xwLjRTKr4vGqCeLt8fqQyAprxy4MZq+2J4oBubUvSHM9PDBWErInp3oecwCCWo/94h31B4Z6PMjrp1k1xU9RzKDRowmtx745Tr59pVZ7oS5rLeWtgy7CpUNvF80SI1jSi6kMdCSjYM8LQfcLFUedsFxTHRHjG7XBZMdYAuUCx0Vz9Y4iGkAJHzk6bFWXY3c+wV8FL8+YU5u4oEQ8TwhQn3bjg1O1B6UusC0kL2dnRJ7+FwXf92Ccf55G4+blBKQO5H3tSw6LuP3oM+9laR6ZmjFy33oYi2M9Rq0SPm/IFkbfxlDrXt0T2Hie9aQHafTbQcohzC8gqegWCerSkj/NrcJvMZEq5yi7u2LguR46Z1g7RMKxe9lMcbbPzAVoHtU=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1721825995", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}