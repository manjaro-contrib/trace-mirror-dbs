{"filename": "ollama-cuda-0.16.0-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.16.0-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "231128859", "isize": "1850498240", "sha256sum": "ef950d4565971f08c13ca3589032e81f4f85ede3a610ae0718e31d0015b96166", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmmO2nsACgkQOeS4d+YuuRWfThAAivxOM592W5CTJzQDlGs3oVKca5+M34R5O3aYdyteDCXKWsqCUZ/zhyCu+mfXKEER4x+TQI8svXglX9nKQl4YrHVsstKWXgWJYf4DbopoF+b6r4NMm9G3VK1GUt1K/6Ya3SM9sEA+fYLkC+3boD+9ABwA6v+/4EDbrYCwjiF9g0fQCji7n/1oN5IQo3WuoMCKN/9aAfB7x3z0pVInpbA9GyHHB3ZXj5DwcIH+tc6giv52NkTE5ciSOcdVqii1mNi6URFAXY2ZSRjGR9AO4lzmiMRkfJrl6fI2lmqUqMkkCs/VYxsDIVebXATyWFKFeKfbZNyUSYxtYfHa8PgHZp5rYWlh7oxnqUb7Kyw7vG8SwEPcTFFhQEwRsGwCA84KUj+35PsRl8M2QBJy+SVzrtr2tzO320xTFjTWa+e+tPXu8ofcQs7ZKoxDs5Z9dOvKtLAAVUTHBPWKS4n+tH54/IYWShC0ow9WVSzmwhS0s8mt/tesfBvtFNQdvfLcRNHjwL5z2eyO4x3A9z5TPJ2ObIOkV8vQbcX0ATJQmODC9uTKnKUThJbeCC5zaaFZWcjBH4xZ8ulzlLdM1bBl0Q1bFenrTQ54Vs0sJB+YexEPX3PLRrXa9vz+QX49ykc7vNBTmQJmyJAj+iZtmdbKFyjvmwf3RDma8orc7DIDo5AVpN+hXJs=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1770963346", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}