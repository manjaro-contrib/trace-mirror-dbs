{"filename": "ollama-cuda-0.1.39-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.39-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "428364562", "isize": "447871893", "sha256sum": "fd61a1e7057f008f8926db29f40e84eea31146fcf028c4abd8d44078c967d45f", "pgpsig": "iQIzBAABCgAdFiEELjbYYgIhSC/EXLfyqRdkdZMmtEAFAmZX7TMACgkQqRdkdZMmtEBgoBAAg90l2PUC1wqltyJq8KqwsiuWvUj7KHWXBnrv1coR9zWKGe+lcDjEvt5FXlr5seJ9eyhygYWVmJ1eUdBQMtDQDJc/u0M5Wj5jjXXxs0BFdTQiBtdh4jL4cez8YTpLBvkvqbh7+jv+QNXvOW74SHEz1N2ouGBaGQ7hK56hL4XzcicyGnsZFQfyDsSnW3iItLgqknnXNg2CWrrFb7sqjHyoq6kbbFrOfPnGbo4hrL+2mVn6fDSeTp5bWHSadrCm/eFEo3KUZMJcH+XXmjW6TzQEy5OXwGajP4AhqPEWbkr+6ot/vXzHpdqYFylpsOFIZMWKnNM3YqOp2AEmRRQvmjlNgj9wjAzjJBRhYgUiG+hVNaqBWTATEbAkPCvxthnhKRzN5fteKf7DwbuU8gPIIcpPyNZvbXTr1hKmHEwkLc6sT4Jlt0xlNMSCfzfENBvDh6auLBgz2/Z5HTRzurwx4UvxrP6eFhQlisFFd3MLHLXXMjtqSMeobhIJd5XrmaHk+m5rVa+UrPijqRaIq/ivH53Ziq3N1Mbvb3VOXpey/hQNEUPI7Rr8UYbED/9ufUuUn5NLv2WRbL1fysv0JGuE/DfXu5GCRxhNioAmptDSYDbr7VCNYJE4KQbY0vL2ipWggBuv7h8K0weFAiKtXdVGopG88S0PS3N9U+gwK25pJMoQJeg=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1717036122", "packager": "Lukas Fleischer <lfleischer@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}