{"filename": "ollama-cuda-0.2.3-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.2.3-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "549576314", "isize": "571226114", "sha256sum": "3006941e21910ea59e1a9fd7bea270141d004f2258263f2ae68d3a69d92ab54b", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmaS2zMACgkQwyIX9vE/8ZKddw//az1qBwle9VzAlKj+K0CeUgBhcFKa5PKr83AvbjUJwPHzKxX+pa4xROG4nOwIdvGYdSZ12ae+h/iFaTH44DRLyyJi6saq8po6vaWksS8fcLtSd4VSIQMoYs0WxArIncGWOg2nqTFvvGSdU40QIzqg+W7zTBYv+WvPz2lOHM+HEb3yazDnky5GKuApbQI/Yl6BwjR8ysMwLR4IG+bhbKTXQIziFGNA+gdlf398ezOexF0yrods9328k2XVdxkGlJIXohtz/GwFtWn/6NLeNnyJsH1qkXQo5mVVYmEKPN2I7HHcuYfkHhv6Tk2KTQ4T5xDO765QV1rYMbI4J8NzOLiKoFYdEkmZUYaLv8f+uNN475p4yLkrhyIiHmyZsrK1FZWp88hcdvknq1zBMdqNnrLM3aEc5c3LSt2lwCTVAUEk8mZOM45g4QzyfTq7U1fp7cG988UAf1mR3KHR3RSCiejslOHI6hkMvsqrqjOflF/92POS1kTwYLPst26/DEUWII9XYswsnSC7Ro3Ru01icfOi8kLD76UrEuMCro3rjgFW2f9G+CKFVbLtnlo+gI/gItytXg3pOvdYHo8qca9Be6b/PQDUUVFEgFOjDMzHtdu36bqX0Q4hrh647Dm6txK6sy8kufdCCMWCssotzFdl2Nd/HHQUQ4Ts2fxcT85uBLPpEVA=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1720876388", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}