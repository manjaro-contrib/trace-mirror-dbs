{"filename": "ollama-cuda-0.1.48-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.48-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "498607213", "isize": "519791970", "sha256sum": "30382d6271a9c6572df17d9f6531bcbd4ba75dfcaf0dda16dc518a52512efa87", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmaAT0QACgkQwyIX9vE/8ZLYHg/+IiHgckbjKw7ozVuko7zZVK9Bp7kLXGwT0c6GZKfjwh0ePSi/e4feilpfqlJ+tvGiZFMsyzPI/ACcpsLw7Ni1tnBkeg2As/X39VRP43ijs4lEjyXO11MTe8t4e9sX0NBX2zvx7DOKK9QNG27PtzU7wsnkhxOZG2KyzYxISB4nQVzxsSwDeSQThKqcfgHlTZPRz/QCWYcW56XvQsMQ1KRufTixoPQ6oRpa3Qifn6fczVneMiFri3p/escvMpyEhouqzBZfh3sjoNfZi9wsr+rC60/T9KkBIZEGvMHN2T20V7gSqSl6DoHaSC4W958TtzavLj5CMJ4NwsEwsZnqKpKgSK86Yi4ilU6Sv+huIemFQlCMosEG8b3CfANNSVWK9WGr3Yxyg/fPZvJejLFr0jL3HQpa4UYcd6QysDYppneAfKpFKbKuFpHzvq7UBcjNhCQpt06bmvgirvK/x2o44/eVL3D4mMx11+v3I07iCQUcXAIWffKhjYJn8oUIN4Ajt8gN6sJnfoqD7k+L2BAlo8jJ4Jak1jUOr6Z3L4Bu2j9b7zFDFfxuE5BriDPMfAJPOH5SeoRiztypqvSk/uT1VPwAF74nK41tx/+TYQD+AG71pGObZPUHDMc8tvV9Tb3oqfTDurvoij2RAj23hhfBP98bmka8Vt4UNBUeQPIPYP4lqOA=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1719671672", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}