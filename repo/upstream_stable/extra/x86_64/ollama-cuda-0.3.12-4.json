{"filename": "ollama-cuda-0.3.12-4-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama-cuda", "version": "0.3.12-4", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266786064", "isize": "292184959", "sha256sum": "3087103738d21a554ac7cb17a393e817c61c11fa1b3165eac232cecd959c4d97", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmclCsAACgkQwyIX9vE/8ZK1ihAAxwJfuiWbT51Dyw8HJs6tIf3cSxYjY89R++g9ey401jJlBF3Jgb83k/jBk0oT3XG+Tg0XRA1NFrWJt0ZEXIW87PN9cudWbCtltDs11wMvLMxZIvwaPVOrTlPmzkulXmwhw/Iy3kWAEgV+6R8wf5YHPZlmJeHZhiR+mvd/R+cyzkS5TGqgmVWiFedJ1NORsn2lMTBCHzEtV65rCmBk71Bx+CT7IQH6oNcvuCgF07sqQq4xDjE2XetAtV3og5vPL70mtOj/NAna8DyqkJjIA38eGx6/IThTe2ybsyyKFcY3GecrQOLi/84CwO3pwVG99hgLcNQmsEapxbpCDUr2IOQGGeRIUg/RNrUWDecqmpLHKVX8OtGC18muJzjqe72PGWM1VgVgiBMvWsydzGn4jWFld/ZQKMXjkcVsX+ZoJKfsCElkT20DeYRSnN/spGBVRhYC6oDh8b9cyrO361oTbKWmGkmliKan8yS7uRCZZmB2xJndAap1Eav0Yq4yeVbQmAfvipekX1mGrIqCURePUhqIwTZ1xjNFvecuPut/NBiv8omJwSCmAp06zbwYEMv8sjMi8K/f+1VTLHxs/YM3b9sdH7MJDbeWSHwpoNWr5ROA4FBqlC8zNldVWVuCCFuAFQSA9BQ5oGw1dWrtxTKqXz66C6t6SFEH/BxbJcv4dcn1YBQ=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1730476062", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go"]}