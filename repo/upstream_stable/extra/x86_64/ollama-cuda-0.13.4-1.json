{"filename": "ollama-cuda-0.13.4-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.13.4-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "223023214", "isize": "1793330440", "sha256sum": "2187e31a1b1f3b1a0e29fe97b0331d3c61baa52db44278999581573fe2513edc", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmlBSTcACgkQOeS4d+YuuRWU0BAAxoi1lGwCBWDG25o8XrjwLVNamOXmLeBd8tQcqGA2z4wwXBYZQkEHVJkgzai1EB1PEuP2R4kjLkYP+6LfprHjnJjEfdTBPw3LvaQlLXLEL0szj3WjUjKEF7UI0J3ypFXMRo+cQRYGBK/hMJ1BPlmFhtYiFs3g1YhAdUTg0BQsCIFhG0EJl+RWzHVD1fEkDgCcjMPDRRmo+oUKahJFMUJgTCOZA2oakK+WcHlIsbY6G7XM45DXgTpqI8DhE3Cs69mXgC9wP+a2M6Ca+Z9e4jysR78MX0BhTjx20YYQ5TSWg5KWX7VzEa2YHUzglowVG8s83o+iGXgLslwUQek0XQ8zhCl4ShnrVPcKfKWR6jNZ2m9gYrb62gkgFpTsDFvAdD87epjXbK7wtKhvV60Jq26madDv98fBjCTN3ksAr4YNznU4r8NGZBBjHH+nYFJtsqV2MRyVyQh0KUnF3MVsk5047VIY8XGxdhcNH9pwlHw+y4woNg4wDYGYJiYDljxtTvqtsVZ5TJkgHPPtTtkDXjz4ib5Gg5R+QK49ql3CpyXietSiTXktUW/xDp4PnldxRgpBCod4KwuETi40bFfy/Oyb0rX6iGdIDwtlqosB0z8FjGdAcBlqf9q7D6csnqtfSLiEUXVm/bVi95wwvvz55RRDLSVYEsqfZ2NvIAcAqegq8/4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1765867365", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}