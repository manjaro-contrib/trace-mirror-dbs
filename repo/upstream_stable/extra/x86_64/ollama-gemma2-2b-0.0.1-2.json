{"filename": "ollama-gemma2-2b-0.0.1-2-any.pkg.tar.zst", "name": "ollama-gemma2-2b", "base": "ollama-gemma2-2b", "version": "0.0.1-2", "desc": "The Gemma2 (2B) large language model (LLM), for Ollama", "csize": "1556492552", "isize": "1629527829", "sha256sum": "faabca1c18a5c42bd1850296055b474ca15e47234671d9809537831a1509d3b0", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmcBOhwACgkQwyIX9vE/8ZJHeQ/+Lg2RcLZjbmlJuYBVPUcOr0gz9DNqc1RHVq8v1wDV7xiSZ3NmO5HwlUSqPIN8W+srk7QotqTU88n3ydFGZ4vKBZ8f3pouIhey44fxrsQ1YemxGd1tC8H77C9lhXac7InQb1kLODlA15vKNhgCifMcYPf0TwxsimS1Rt+/kvrB1cVL+Z9kq0W7zigbA/ZTL2IO9f/g1SpcEOEi9AXSYQDM6WATqg2KaALJ7sRWbsK2f2Z/ooGtALEu1D2ZI0Cw9ilbZPKc7wNYqMIporn4kzgIZ8qaoYSkmYaxGK4Bsd46bsgegaBqHFvh6chea4R0AfT9rav2Obp7K0sGV5T5u5knMQqjURHSVyU+wlrbyWxPSJszZcRuR6kmzX9Qy/ykDIh2cQYt+lzOmmX299DGJBxwxpTmjiI3PZI16bvAP1CzmN161Q3qXleha7Tw7YmZRpNjhrfqIKR5mpL7arhY54/Cp8/rh6PQ3wdnKiCumQGyEh5XuqbIietRPD3csINRsBVVsAhhwUXzGGWWV72Dp53etfBYeC1n2/gWRss9zd3wYGj8IyerN9oIocO7Y+IxaOzFcWFHcBNXDep7kvgHGzLSOPUs9ozgSm+PVDvDVWt8NZr4fRFF12cyo0AvC9fsQ0O4/fkh2s7epD+mQLuJ7ibe/u7QEMmC11MZnhiitg/NKmQ=", "url": "https://www.kaggle.com/models/google/gemma-2", "license": "custom", "arch": "any", "builddate": "1728133495", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "depends": ["ollama"], "optdepends": ["ollama-cuda: for using the GPU", "llm-manager: for configuring which models to use for which tasks", "ollama-rocm: for using the GPU"]}