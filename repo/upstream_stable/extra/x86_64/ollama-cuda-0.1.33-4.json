{"filename": "ollama-cuda-0.1.33-4-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.33-4", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "427036308", "isize": "446324925", "sha256sum": "7c5a71a6b9c4e70f5df9b6be50b1904c0f7e4371b1287f8234fb176ba98f6cef", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmY2FXwACgkQwyIX9vE/8ZKsLRAA3zvLUE4UjggtrK7EuP3drUHu6ksn/9+4FAGTmT2F2Ks4WZQVO4Lk1nu1cCO9PQskbBaqaZSHIkwsIEHCGUMn82TYMUhJX4LgxyIfg5JbMmttJSkqQlmlOyeuu3i3UP3V3ft7pND8Tk31K52fv0NgjqNK+XgDoQB1xV8aVGjeMyF/S8Oe0M4MpzNEjbIXHhewp2RU1aXUT3/q1WwLDO33dUVEYxHCI0iar5EqlsrElZGkN+AD81BkOLgdzkfP64spB6PdlQ1dxOu/8+aJfkSpfD4G8Ibxsgfry1P/2OsQ6yzewYnWCIXx4CdzJMvoxdSzAIshaf4xmIY3u7uCrTL3JGg36buMBJldvzmT9/28WkF94ZhW20dcVLC76pFHiVJLytXBHbka8E/CfY84XoZBW5wyAjx5cPYL9tiBABrMwCEPW7jnlsXt2ykzqmy6KFcT9HrUzgFISvQnYq8GnY7IVMdFd5vp4m1lBhGK5+CQAP0STJINJt7O7jDS3TBzohWCD7eRipOjOQEXEP82YDHWBheHIXQYmO/hzJpNt7RFEXAyS8lXV/BD5dDaYvG8Cffhl4THcKEwYAor/sZ4dQe0/JDtJ3zDOpX4IWUk7wruMzltoJxkuU3PYG/fhTniUbCK513pD3JOcqnZ480LfsyJr5w4iheUs2iG0XydfB5Aca0=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1714813260", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}