{"filename": "ollama-cuda-0.3.5-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.5-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "596213411", "isize": "618633386", "sha256sum": "1eff2bbc3513b8aaafb00f61d53e7689dd924c177cd63119814a4a99bd4ebf6a", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAma6kaEACgkQwyIX9vE/8ZIaPxAA2aa65s9qpPbCot5v3dgnfp08dWApEqiyRtDz9RD8HDNarUwEonsiLtIenp0pr9RQV2RBo9+GA2gO9YOkBEy/e2ooSAfCOACoFr4yZnLmX/wDgy0cAbP6h+JjBg/z3beS/pFVUuWDilm7EoyGgh8g3JdjbswNDqw5XQqK0mR2zVigtKO+HvTc6LGn2Crszg3PVioHpT1Jk8R3gGOdJJuzT6RukIepGu2f2TJbAe+Jvf+/xhWs5mBDw4jxqu3tOx/X+okkHS3xdLL2dJ8/a9zudlZx/ZjIapyXtDXhOJJHI5mBbSP7jI2uThEqJ+wavBLsBPri14gH5SaJYnv2KKq+8/dEF2C9ennk3Y1WpCRiSAeTTHEWzZ4fe8902ZIvWP7b3PU75eLLe2a7QBdq8B7icLL7J8tK2/Yq14vSiRvWJmhlUIH+s9+IhVbeCeAYqHcuwaP05Jfm8fpwVFCwXySsV38UL/NILRdwwBG9aaCcwgVBbXeS53KwDpnPGceeRKdvI2mZoahBEWvXpGNgTNggn+wS9mgeXY9C5aG1sGl8NKv/5J+G2xl50M0h1zlWyem3P1eNWYBGZUVixHEGOLwXaOZeceGHMPHwa2YQRWpx9kHQAAVeOh2avX1Ay5vs5pgRqVILBiMZWJoWHVq6p0qw+XUN93gVq/JD+JDXkVDGlpo=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1723489400", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}