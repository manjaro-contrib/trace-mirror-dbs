{"filename": "ncnn-20230223-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20230223-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3620042", "isize": "14819931", "md5sum": "eac24331a107a5707f09eccc1afa9b74", "sha256sum": "56ae5cb695fbda60ae6a2a00e9bdabde4a3dd32ea744c31915d18774b9499bbb", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmQFvHMACgkQeGxj8zDXy5JObw/6Azn+hf3e/WgPY4H/EkW9YC1bd89J1ZET1YugixyjpJmjqXD4a1ycYcdFPvY7kyx+aTmbeT4rhBRuN4UNAsVN+NDyiPxntL/5IAl1psR/+BNJbqkSERZ1RZk6HN55kj0/I8qt+rpYjPBDIaglZGjGDtt2LXI2jIF0pvJh6KmU7VKKsnBW+h5R1pwEeiDELNkBzgylHxardY6M13GgRdNg8sqrRtt1m8mzfiEUAdsGUskubf7EPjrGyuZoEIXAmwGXoFoYlBb4aWz4WxaucJwXhJ6fwj+jVIEX0OYaDlfdJ42JiMomNCNgjd98DxCPKFdnmO6eGaQ2YA9UFAgvVDJN1t32AmEnRPQse81MKqjimQ+v3UP5Lus4CLxCF1R8o2uNVHjkoP6SHWA9CubZqTNQ2wgjqzZC6COLsQ9W1WDtjGgvW3SF8WFqlRAOV/7DwsPNaf/31iZVOJErh0YKXRMtD4wnyDvALPWo4pMSIwmSyYU046t2tFOZ5oix9fJhy/M8qtH787lNikSHkdSdKS0tj0JV/Fut3DZteAhIGRaiMAdcdUr39AJWJ1WILHWlVwHIKobwdGRe5cUnnOfjcU1cp2tKULbu5ztPXCDpE7uxefvPujvvX4Oxx3mVkxAvg9Z1ce+IwH667nmtiWoKgVrEQj+YUZJJudQoBqqltp+buDo=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1678097312", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_x86_64", "ncnn_stable", "ncnn_x86_64_stable"]}