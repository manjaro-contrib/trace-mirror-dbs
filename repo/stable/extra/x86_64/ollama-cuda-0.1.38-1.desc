%FILENAME%
ollama-cuda-0.1.38-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.1.38-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
428343490

%ISIZE%
447994749

%MD5SUM%
a2623d237525d911f90e9d05fecce4e7

%SHA256SUM%
7ed078ccbef4eb8a3507fcf9c38629ed6957d6025ac6a9c5ca7caa341b5520b4

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZGioIACgkQwyIX9vE/8ZKkxg//WHE855sxLgMTA468Ho6ctq96pK4QTgFQTFQe7qhh3okEpaLLB/otU+FwNxxiuwRIlLm2Ko+u1vLvNvnmckTzxyy1GP0G/JOLGiWEiiaJgujSL55wvYKBQ7DltwlUU30WN6XlMdli4hG0/HX2QjI1FEHfn5+H3SQP0bVWKhFkw/p9qO2puhQSYThGv5X3RAS4KjFPA54mfT/7j1pUgEdvSQHgrkgVHZVeoZGmv9d24o+Erz1HXv7zKQzlhnV888o9MqjXtfUXGTdSiD/TJJzHRm+iTYAPcsBqbsMwAePFM1sDI15o7H9Vv8Pn/B7ABDxT6OmcRE/VmvrnHrJFORW9oXq7ghYxKmTkG6daHeHnULxOPBPsPt8R7V3U4rNA545VZCBcGnXDP0XQfsmUdpC6zxYlEiEGpxSIF9YfnBmbv+Hov85PzMbTQ/bEftLCZHz0JcnLWjq4yKlJhVjclhZ77Dmvk4vSY9XmBafFkN/8VwJCdd3HCvRIw8QWI1mGlBS36YLh7qUz7gzHc2JyzO3/G3FrZtXLwNXnAeY/AuRMcWIGWrSsT38y3UaFd6QV891/BmmScynyXqxAY+5FnwKG9mIEeXxM49UZg9Lx+oQlZtdPau7TnibhKlyiOSXCrpGQ3zJmQapd7Qot8vvDB4Q/FrqKmgQPzmCTFyX64b/6p+U=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1715896151

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

