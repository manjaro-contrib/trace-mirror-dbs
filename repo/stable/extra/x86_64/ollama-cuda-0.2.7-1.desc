%FILENAME%
ollama-cuda-0.2.7-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.2.7-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
549430504

%ISIZE%
571365538

%MD5SUM%
31d513e989dac9e5f50023a882b94c3a

%SHA256SUM%
c8d5b6ee90dcc7eacf9532ecc07a8a0b5f2633c95eedaf006a6a4cbe46830328

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmabtewACgkQwyIX9vE/8ZKQFhAA1mrDtrH3sMQqFWW5D7DTVYH/mYSOk5ixMFaZwgBeYEP+alyOpVAfU+dpkEgryISsfTQAWiYkV6XZoHqeK7oXgCOL79iGVajneMuEBSoPY57845no98BhrVRiWUaP7IEYkoRMR8xw0M6me0R23oo7gWxq0nI/IOBbSLmQuzJ4dpC5izsNNz6nwB3ZyhCH0Y5Fn9NDIy9SfXyvA+ChHblFTdM4pxclF+cSMDtEzFXbPUXptqm/cthVs9s45OMbRRQvr8gv0VjZD7pZBBigplhsonM9l/aTKZvmi8rNJm5EYkAaDp+6kKeMj/wJoCdR0ad6gbKabOeNZ0tVc/SCOQUgPB/Fr4c8dTDWVn6S1+cJOG29EBQTFqZlFXRfW9XJuQkPlGbXsfhXldc9d343KfMdc1vpygFphvrDjqnulQVCCfRg5NmcP9iHraW0XcoAOCm55wVxahZy+dVWcyWApdWRrCwWEL6OJ1nH8joH43xlxze8YvYT+IDTDJPCQoZ2Vn2MQEMwpXHdQDIuiI0wdUKAZaiP0D7L+5/G7QVP4u1LxSq8ZD7CZhUJopt4EksrBdf9KcpXoGb9Mp8hEMjEkF8hUAWr5f27EaDgL9vjy3qsmuu5OQAs1++5I4PjpBD5JPSb/gNoli3Hr9lY5JNv6dtKIb/3dg/McE74nkVVVnGySwc=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1721472613

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

