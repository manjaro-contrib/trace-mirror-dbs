{"filename": "ollama-rocm-0.3.9-3-x86_64.pkg.tar.zst", "name": "ollama-rocm", "base": "ollama", "version": "0.3.9-3", "desc": "Create, run and share large language models (LLMs) with ROCm", "csize": "190841670", "isize": "211059689", "md5sum": "dd9b013ba74db6d61cd60d2e3ce75c69", "sha256sum": "10901d53e7673d15d3700b4585a5a69e99c13857bf3cc92475553ce042edb8cb", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbYoAwACgkQwyIX9vE/8ZKcUw//U8G6qxUU/AhfAvoGNkAX94kWJqtO1hLXCMUuU1Ua2LRppvhqEwqkPJQU5mW5he8TDZ1AxSMabRFhJRUZGhyRt/iqJPFTw7U4dqCoBCMIo3FJAeckGGryKCgkNSuX1Gzc5uAhxGP5hNQ0UJhC2V4WpGYIcfxEhBCbsdsYDf5U3pPCuSQPhwDUuDWYsHmJDM9D7Vw53ZO5XdFp+hxwZjw8t9d/C4hd75dfZlConR6TteehyhWOM6s8cbX1aOX3zf2rA0QG60d3Kq7+Dt38p7UQUSGCDGGwLfPXBE6f8gvC68gs4XSMC82SfPey2fdH5h6o2AjH9iAjM++siEVCBuvHSljs+NIaU8kjmg2MEHCGwg23k0Jk66BJ8+ZLEVUSX3g5fp5uM+oIfT2P4etDk/xODknuMyCrSRZe58/+gQVZdUqBvmYMkekHLs6pXbk3IKuGst2JwKxPnd9UUtDC6/KyrCRjTOgZw+uDdwZyXmIp0D1q/7cZpCdDIV2Wntn3CXM1+SPU/QdPapR5tBaA9PSGWCLG8KDN2AF9vmOesOQ7pz7xmJ8fv2Du/TXHLq8woH6vL5ZFdbdIfaRqppjx55+Anyfj3V1PvuyEGzuZpUjyUhpdlhzOKe6JVsKrNzXFhJonGIj/EEwPMr46whYcsFfB4/60BV+KCKL0eOM+YnDVnPk=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1725460098", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "depends": ["hipblas"], "optdepends": "rocm-smi-lib: monitor GPU usage with rocm-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}