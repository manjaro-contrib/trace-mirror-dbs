{"filename": "ollama-cuda-0.1.24-2-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama-cuda", "version": "0.1.24-2", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "457887566", "isize": "468537693", "md5sum": "c19c9a7b191110d10e9e4f2391f7447a", "sha256sum": "f0792baf49e76b586d5f99e26ba8e4ad7c6d142468ffcc3e9daa7555c24d6877", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmXLT+IACgkQwyIX9vE/8ZKgpBAA2BOHnY/eiFF/b3qtdH+C7XwvI5xvtzPOuJuNw3KtNUsRZOPIegPM9+iTixWsqjpP8TlpAEWaf+JyTb8d8D4IPDXfgrS/KVpEryzlcjwabwgL4WjDi2cj6Cmp+pld/RdJHP/elL7IpzMxOUOkVO+QDj7UIwaJ5QBJm4zOY8+apbDyvSeIIiTCfx2XoppSg59l2ip9XZIFvwXuSq88e7WCWjD0CQ/d1NlUcZX/7ZZVrqRgqlDVLm9UyufliEwje3TQuOy/DpF4ZygmkzAxkBdK8oVSKedyTpenR4tMM1P0zVCEmaGUvSyDKPmoQvBACfZUpTHlaQkVsenoLewnPcK4QbVK/7yMtpEHAn5d8kYgPFhYtj6yw9+AE4YpZeg+pqXGjZukzjWT4mU5dxm2eyfks88i2nesrEX0WIFYlpKgPAxKQGJJa/j4kzYBsTaklsAQY75PV/F/7L/5kKW+2b00uWEPG7oCz7b3SK27jYkiG+Rw6mSuNCKlMM96RNscujXeQphNTJwDaVASDUmFB72zNLXAgj5BJKRKSXSp0KTOgdyg7xdj3z2bq5d/9M5FhZbKvb66gBY83eM9E3TNU3OWzFnUjK16V8CtkOMoH6jBnbh7n/5+Jr+3oqAa6dXc5FCdiHRjfnsAGlcKZejmtkxAZ8s5AXbNwuRn5unrJZlRgqU=", "url": "https://github.com/jmorganca/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1707822270", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "makedepends": ["cmake", "cuda", "git", "go"], "tokens": ["ollama-cuda", "ollama-cuda_x86_64", "ollama-cuda_stable", "ollama-cuda_x86_64_stable"]}