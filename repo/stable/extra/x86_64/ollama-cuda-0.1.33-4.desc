%FILENAME%
ollama-cuda-0.1.33-4-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.1.33-4

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
427036308

%ISIZE%
446324925

%MD5SUM%
527df3df8cc454efefac495aca48ad7b

%SHA256SUM%
7c5a71a6b9c4e70f5df9b6be50b1904c0f7e4371b1287f8234fb176ba98f6cef

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmY2FXwACgkQwyIX9vE/8ZKsLRAA3zvLUE4UjggtrK7EuP3drUHu6ksn/9+4FAGTmT2F2Ks4WZQVO4Lk1nu1cCO9PQskbBaqaZSHIkwsIEHCGUMn82TYMUhJX4LgxyIfg5JbMmttJSkqQlmlOyeuu3i3UP3V3ft7pND8Tk31K52fv0NgjqNK+XgDoQB1xV8aVGjeMyF/S8Oe0M4MpzNEjbIXHhewp2RU1aXUT3/q1WwLDO33dUVEYxHCI0iar5EqlsrElZGkN+AD81BkOLgdzkfP64spB6PdlQ1dxOu/8+aJfkSpfD4G8Ibxsgfry1P/2OsQ6yzewYnWCIXx4CdzJMvoxdSzAIshaf4xmIY3u7uCrTL3JGg36buMBJldvzmT9/28WkF94ZhW20dcVLC76pFHiVJLytXBHbka8E/CfY84XoZBW5wyAjx5cPYL9tiBABrMwCEPW7jnlsXt2ykzqmy6KFcT9HrUzgFISvQnYq8GnY7IVMdFd5vp4m1lBhGK5+CQAP0STJINJt7O7jDS3TBzohWCD7eRipOjOQEXEP82YDHWBheHIXQYmO/hzJpNt7RFEXAyS8lXV/BD5dDaYvG8Cffhl4THcKEwYAor/sZ4dQe0/JDtJ3zDOpX4IWUk7wruMzltoJxkuU3PYG/fhTniUbCK513pD3JOcqnZ480LfsyJr5w4iheUs2iG0XydfB5Aca0=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1714813260

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

