{"filename": "ncnn-20241226-9-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20241226-9", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3086004", "isize": "12237238", "md5sum": "2fd7001bf93b8ad91b044185a24bd209", "sha256sum": "ade5d7370d2d970851f7ce839c52bfb73542d24c667810a771342b2ad25bd906", "pgpsig": "iQIzBAABCgAdFiEEJipY7GxR9+o5Wy4t/cMEC5Ksp0gFAmhKqXYACgkQ/cMEC5Ksp0j6KQ/6AwISpiWdv4K8aThH0JjuC7y9rqxrsmJD5ySmh8CjTKkZaZ7vYL4eN0vsic8hZ6iaybXXiPXUE8aa7gZW3EE34TF7VbrFcrdl0mOpx8XwngJoVqlc10VTcYL25ZxZMc8eEvC3GaGLKQN0MZlVTcyWST0Pqu0JrtzM6hs3OCoCsajucUgzrL0CblROMKoUzVF3Xk3qTK/tn/GmDNnXmylGxzCZoa/23QZCSE8FmE4gq/TE9NzHMjtEP5V4zSmtZpYKYfYmTfLXJMqCY6ly+i77LagWBx6Jt6shj988qARdfu8hAL7YHQtV2/NhyB+Kpv3OQV1PVaTgafDwhcKzvclOnpInjZruGGUcW68uWKALaP0x6CF+mj+GcwbzVk5XGOLOY2Z347YmpnSpagA69ti3Ib+p2YQDC993qpR8VlYAw/wf04B0X0E2o/QJDJqEvCaZvGVlr2PMCdiGmmWNqy2TE20HtFQi/ZZoUGUj49KJZK6omxr9l04ka1BG49XvbxCFrItYEfJCP9A+YLFGvsiR+KEioZzKrdMFz90OFTp0+JvET/5HbZ3go2FQG/rDeoAmkHWQ+EhAWdBylY+cZbrOmGEQWRFIKmv5hFUxDn5Y4hDk3awuLoa7FhucQ4wWio4kaV0ZdyKUB4gYJbouusn4MQ7A3qXrU/3nb+36hLcZ7VI=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1749723427", "packager": "Robin Candau <antiz@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}