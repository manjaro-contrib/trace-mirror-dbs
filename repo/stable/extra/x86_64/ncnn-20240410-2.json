{"filename": "ncnn-20240410-2-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240410-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2771788", "isize": "11436571", "md5sum": "39c83e4d9d2da0ff785b56024eaef0ce", "sha256sum": "172c0a84ea1dad3a515ec2228166d5911a12d7650ac4ee130dddbd735888acb6", "pgpsig": "iQIzBAABCAAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmaw2CwACgkQk7EdqkwZfj1PUxAAnq4AoKxUImzSccR+xbqKu9L5uo1zgI2mTQbGhal5NoylRrDgZ7sWJYbO+5JjMJahfSkUpDiBONujCWvGNNaTRKGNpR6vOeDmdllqWVW5srm43ULHEx4isGJ/GRxd9kkd+OTtnfsY3AdUwlv1YEOPjm1I5kqNFmqEtPICZxKTSxc+1l/Q9R70P8F5EoRQvDUdNJ+SdKwEKetKuD41gLwFp34iI1HBx6TCrmniugIKbMKml0CtuW+lA8l59ZzfyQWpDVE0xeROq10eqxgLFh1fprsS1EDMkfbR4aI687dTCPnR25ldaEi3vkmt4hkdicRiARQUuqneZHCWfhLeA1vvP59htCb6oufCJ4ia6mtJC0OvB7mHlyNfe7+SHn8sJdveCzSN2kmEd9lQSXRdwsLpaFckh+hZc82QPdDe+GoFKnbOXy+FAaQwbrdUMO4vUuOVQaBNh6rGEk7sXEpQ4haqD6e+pNhixBmUIWgJG3NBV5KSolkBIKOBSHJ72tkZBJILB73T11weBu+X+NL1vkdVRD+hIdHjmHbVswvvhAeeTfKGxvJLeRxGthCgUqSZa96phMgZKBJeGwtJY7yc1IjSHqV09JqmQrhsx/xKvPcEFpSxI98YKD8cgzuI+bCW/6EDY679olTokIJe6Vd9IqO0muujEiGMYswUUkGkKwbz6rw=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1722865627", "packager": "Christian Heusel <gromit@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}