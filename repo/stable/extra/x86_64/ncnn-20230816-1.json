{"filename": "ncnn-20230816-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20230816-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3678446", "isize": "14827322", "md5sum": "c61c067ebb8b6fcdeb19f8b860a0a695", "sha256sum": "b3c425d41082934635130363191f200be53adfea3edeaeadb943778abb5703b0", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmTuMW4ACgkQeGxj8zDXy5JD6Q//f6foSbjQR/PlHWLfvb4x21UbkqitiPRCd7LUkmTuW+hkMJAShGaNpuqI6KNdnZreUXvACmLlwxZzz0JVmFpcwTwWmSmDo07lFoABVgyqh6o245RAEgS/LuPyTFIKpQL5lP7WZW3hoo4BZNxHtN2xp4DGouFx25WreuWyUEecbPQsnEmyY9gqWtKbp+0fSiLt/s/0iaqauL6TVIZgWUkNr8FJ8qkDb/2OYiXhE98XCil5BAAYPAjV5m+onbLAH75H06bSOJGSGlNSdTySFR3zhY3wOHzKnlt7uvxz0yWzVZJXkW3966xCGjk4iO58iZP8xdMJYJQWeGEOETYlKkFpfL2H0WsF/6yFdt/jg5buNFPMNNcoZOnocMw98UTkIC78N0W5j0rhehD2xztZlTcBRgi9j0nYSmyb2Cy71jkWO2NyX2KdXfHqJQ5GnYbrCfPdzSR8655DOORdUUpz6+m6QJOKDKGdtGMJALK2zrBY9vqa6XcjI4V6nSZ0njE7Jrf+UwoALBg88ZdYU4soJ/hhhwsy1x6rJIg0jaEVCQtc3UJrfiC/77k5sEHK03ahjm/sbX/1B+AFbSVtHThvnCgR4yngx8e1unYRIpbN+1eQN8Fuq8QVGHW0P6hem9l9hqOCvTPvbFQ79vD59H42PcwDJEd7+ThVSlNdkW/SubB+ENk=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1693331618", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_x86_64", "ncnn_stable", "ncnn_x86_64_stable"]}