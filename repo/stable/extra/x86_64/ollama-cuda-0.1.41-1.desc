%FILENAME%
ollama-cuda-0.1.41-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.1.41-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
447958654

%ISIZE%
467905301

%MD5SUM%
6cd2bb3e7287226f51035c82fde0817c

%SHA256SUM%
efd8b610063e3aad71aaa2cf4eb9fbfcc01a9fcbc965e58b55d1152ce7e9b1a3

%PGPSIG%
iQIzBAABCgAdFiEELjbYYgIhSC/EXLfyqRdkdZMmtEAFAmZcn+MACgkQqRdkdZMmtEB0QQ//Z+/3d8+mejy4dz2C31YFeX9CDw+wfstC9g6dPUMPWvhmNqWyKWjC+zZoPawT9ReVpsrJUm7sb2LysbdpOL5EheZqZJna2NdYpKfagngfF9H9xS0A1TdBIY0MBzq5Xv3cxV1prmJznNhnFUeNSm+Iftg+ZEcZd9bKm8GcEgkd6dSn/QLvJh/cIFO7gDTP0HeaoWZ0/iIUzzfp5GeI0oCmgRxVDzwIL9S8jCnTOaBcVTK53Kjb62wRpP/xAXELNXFsMRAMEDMNPa7Un/NplXQ5Veio9LC4Q3nK0P9VZzyP4UuyM9LjkwYJ5XDunlP0kaPOi+sD1P1+dbasS+LgBrIn9ROjMqv0/UyFig6n6s4B4FP745adBphn875mVwmyDkf1Exg0+fNZEvP/uCnbbz+tCiiFMkj0/nFNMRPPHhhboM+c9u6vQjW2VTL8uCX0ujdEEGYy8gojIYsNoK6qrgA/lESGoABJeJXEC0cNJTJ0tnMw7dfYMNrqmgTcMJDIr2/XZcjDcW9P2iyClJYNM6l32/OUbVzSh96T9tGsuTWQHiTHuJxtAYDG+ZaxAqqrSkb9KZvWjvbmJw5Pd4dXxAUQjHgpem5yxeINMfJ6bVB9RNIOYP1evdOEiesXYr8cmAmO/sAVE9318WbdGjDurCOdDsmQv+Ascx99/U5t+ltY2HE=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1717343505

%PACKAGER%
Lukas Fleischer <lfleischer@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

