{"filename": "ncnn-20241226-7-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20241226-7", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "1922700", "isize": "8909550", "md5sum": "ff647b648c6aacb0c59cd25c8a05fa5a", "sha256sum": "bd6f71bdb9f447b321ecd1fae50fe7b8c5a4d031bba583a73765cdb2685bf82a", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmgf2NwACgkQdxk/FSvb5qbzpQ/+JhNsZ5gReHBW1JLG5tZzWgWu/OUtaSh5XMuAHhgwmG+5/XnwY5TvTf2qMXJES1zTWP+RWTGS3/dKUvlRcNsJRSUkcEsmojuaMXTsuPmWOpdzwlMLrvG4NiaLBg8M0++vxh/qJKdgVEkVe9cC15gAybzQRBmSJosZNPg0Vayaf1DgsR0RGaUGSKO96QF6exyCuBF70wmsxFbWGg08y5Ef/8vbiFtr9h9+lSH5EgwQhMABFraQkooCWLbBp0A3WDrkZLXSd1+NtwRWmhMn6dFXK4ils0ZMsVoaA/Hz9lwZYkMcI32kOQfgeJz8Ss4G2Lg+VEDKzKeKMOLD9pFs3pPt1bMAnQHElSnXzdUV22CXeJF+aHHo+lV/WjvKtdAlS94jNMRMfVL1+mrO7T3GiGA33AjtXVXJuMpo/BJRbKmn91BidLFHQaarsPWC3A/gMg6Tq9lv8bEBmL8s53nh/NmdMEVvf8JMKZ7c2LDv5U6itBgVCaSQxQ+wAilSt9hvcnuQUfNA37iy+4rVxRJE9OziQjP8AqYhFoMvCaSwqWSl0QhgFX0P1UpqEr6AGT9sBIZgyVRt7Ody6BywN+KC5Q+QA+xUn5gvpcifEF/qKALoKV//Oyi9jKmoOR//fYu8oblKLMsFmtwJOJRrbhFsQZ98dlqzNn2QAdTuWeFUBy0k09A=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1746917426", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}