{"filename": "ncnn-20230517-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20230517-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2568260", "isize": "11797610", "md5sum": "1094b5319de74c4fe3fba6f9ccf15c4e", "sha256sum": "6d4cd7ed0af19fc9e093fb652a0adeedd116311a786c397547e5a1a67c1ce22f", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmSX6XcACgkQdxk/FSvb5qYe2hAArGsl0pEHLBMDYDhNW9KB8BCmH6Fi4D3+tj8KtGpDIJHO3u21Ugev9awTwzWY5oLGHJ2LL3K9dwNvr3DD2N5vrbofnAP9Ui1U01syQubgzjIBPgMbkGUH7rw+NCi3l1AUAKoASjLqNxMtU9wC42v3zU/0joKEnzx6UuSAYccpz/E7b4nlF099/d6P8gAmKHq1RFeHUrKyV8uKJ1rkdwFOdsfWsZx0IWaxfnymIlm159G+VB79elu6ek0gvZzHSG5Cj2MiQhPMRziDy3rr8s93goM62efhe5dIKlazNPO4dLrmJCo/uWLR+CBCwCblhfcW1EkkhRoFqsb6YCK7I1D8rtU0D237UWoMCpeXma8Y55wTKlDMZl/CI3riMTNnGopX8FaHxEoeGQZHnLGWPAtRkmrH1R1r85A07nGQ5gzD9MUd3aPYj18TO9jF0LXdBZSQuZyNgrPmWcsmpXnfgJ+x4FWcyf98t30kh27PPC6IOliRb9z1+WU8tXvdW7g8jzkTTIjtySImdVLvWcnSNZFJActIgfr++rOFnfioYk9f8qsq832wAIG5Sj+UUf2yVOi9Az0/uZbIWfTQ/BvJFxEFFXqj3Ht/MUIwnSkp7Q+16MYI2H+azqt8DMcHsRMyku/htzK/Wx0o/52jIOjkC3ySW+8O3svJXqXFQRZrHRLnv00=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1687677060", "packager": "Arch Linux ARM Build System <builder+n1@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_testing", "ncnn_aarch64_testing"]}