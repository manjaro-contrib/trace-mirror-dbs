{"filename": "ncnn-20240102-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240102-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3868304", "isize": "15587801", "md5sum": "642c0f7181919a9fb0a38b5a7a3d0dc1", "sha256sum": "b6fbf7e57438242888acb5b7fc1a7379c0d88faf0ec3c51ca0ff0f771474c295", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmWc+B8ACgkQeGxj8zDXy5KIMw//QXvGpxD9fGTHGqgvn37GOcrp6MLN+2zCFSjsm58MuI9ye1CsvyC5hUDG+w6ibTcfDkGBRiHT0xLwHcC5frChGIR0ri0YJXL2gwf9ff/J4a3UX+mwSTJvCOuD8ziMMbc+sgTtn3ngnHSHPtcNeO3F2X9lt1Avk1n59jx8bqlgp2alAvFZ5g6EtZcFuj2TMmj6jk0HOnLFHN5Nl3nXG9Q7FSJMGdWbLw0URp2lLN08jchXFcoXNdkGh2p6neMPcFrcNA7W/66F6lrOcnsQRnVzTWvAZBgLoN3D4ojV7QbdJ31hQ6IcBFxrgVQGG5Ze4gq7enpNaF6t6Ryv1iFgO22LewTBjsk9/6qft0QMxDv3le/GWvpuo79ogTcs6nO55U31yP+hYg4B0wZOnzhcjgcIjnJTDoYWryHikQoyW2ffxZvDSpthd3oeB1jE9MWGC4b8QHO2wtPYKBxnsAMABp3iS4sRjXWg20t6MI9KMqcGTBsJGhqmCuGiuNKxaYUkEbrzAV+a6fcv/vrt92hd66rPCbHBw6kpsCJ7/cea9LqAtR3XDe12uhZeU9pqbSny5efXxZUK2mq8kjZYjshq8eEy9bCfuQW458GqXA9n1p5jjLEKqJzhIJWPqA7h8k+e4SjwhdUt/+kq0UmDgr1i42abz8Y5luL6Wjf+yZ8Y+iw6MGk=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1704785049", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_x86_64", "ncnn_testing", "ncnn_x86_64_testing"]}