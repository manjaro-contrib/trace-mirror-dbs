{"filename": "ncnn-20240820-4-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240820-4", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2912630", "isize": "11936573", "md5sum": "cef3666411243bd865d70840a28a003e", "sha256sum": "ff0a93368a265010cb26f55c48eb959941a4b7990df379cee3ad51ae30e5cd39", "pgpsig": "iQIzBAABCAAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmbxulcACgkQk7EdqkwZfj3ffQ/8Dckt0QPDVYbSmWHsfOoT44seC92nWDHKr4Fv6N96B/7YjaWEC4juegLpoTt9r+gmHqsHE6zTZ1EWZjXyBVlO6SvO9fhun/OMk5DElnH2FL1uwsKtdbyiMK+aVlfvALOzSPxvOd1RO8yG7M9ojv1wmCmlFRHIbFCqLPllxVOyMdhpbCImnQlA4ELWXQbwaq8pnnI3Gb4H49+q4iRF5UI4+CctiU9iwR6wQSYnuvpDxWNMxJKfkk97QiKKeIB9TBY0YjIuWyJ8u6yZE2QWEgBCHKL6G/k2aB/bF85ycHguyQn8di8HGe7jkeQvpPu/iEffShWAIEixElVXigHPVKMErG2r2Z/ejs5Yy4gYUZP2KuxX7toU6NFBXWw+OWx0M6FJ2x+fIgolykl9OmsFP11Fuztb6vITpY2UJE3YiaE8bgPSKgVOSvPRQA2PJFo6Nb1Tlq4PXdL2Nhv0Qbjm2yqk4U2YFq/7ixYYMEW1EQwREPjg+Qi3ODtP1T2ZSAU33eDyjoV9t+ZV9tDRy464AuOiwjYYp6wonuGiRrZyQuuILvmFGVFwQchQ8hQuP9nVAbmF5SrU32XxTUTxy+C9Xw1pJ+PwqXEuH+sYL9M8g+Gy9tImaAeh0dGwFTkx1l1xGTBjA5w0qqYqovmD2IYKsqXjxOclbk4fh6D7DTLx4/JrH5o=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1727117833", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}