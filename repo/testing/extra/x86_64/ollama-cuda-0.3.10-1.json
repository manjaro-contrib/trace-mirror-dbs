{"filename": "ollama-cuda-0.3.10-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.10-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "266295830", "isize": "292077417", "md5sum": "2035c34ee0a9cd3f4fb45bbcb1ec6642", "sha256sum": "7b70dc80ac9eb1809b2a23d27ed3ddf880e45ec6b8b9a87d4fb7249bf4692391", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbkjQsACgkQwyIX9vE/8ZIjKxAAimSXqQAfOxduVzy5XCe3SSliBOicMW9Y/oVoTMijkCD0OKgYM+IZDgYQ1tC8iYwzAIwNEBQtw3itb1Aon+lxkuRSXlftCXfdG5zk+YXkuVzFQb0wWT0oDknPPXnRacl7XyjsHKY/rNSE8OnbYo2a/glAgKzMff0dPFtfAzo2sJqFn0h+1ZtBK1ELZQYfWAxWWCM8DaRPREDHt+T0/xEgkYWX4BWBglGKZSvEqvT7tQ1+4nEM63A9nOFfz5WB6s7yRt5xSBwmZ0BjVk4NVf/PNbV8ouqsfvda/0wJMUu0PlBwgmIYhrl8bR/h25X5gxUeBuKexQkwihj7NwXEdV8yW9HGgcog/eJLXG/QcB17MSGMuNUZaQ63Wknqvs9eskz2Q/pr4fgyTVMs6PclYSUvjHzM7HPzGAut3W0i3UwDykZVJAqTDkKMtRUikhnpyuISQft+xnZyGsSlhakAaVL7itMJKAXl9n2ia2Jj8e4+tXbhopbKbOiLq8xOOISZ8td91AWZ72wsqjCZyS6uloVQhDvmSwhR+/kjME1DuPmOqlxF4CFIu7jvXzHnGLWgu8EfglAPNAiWEiTZi9F8pW77T4tkTxyFXNuq9wyjQJ3arDmoaueTgeif+aoTdinr+IbAiZKO4Tts1zNB/RMMQbk7LxcD25GStq8WChQkxM55H5I=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1726234279", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}