{"filename": "ncnn-20230517-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20230517-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3723361", "isize": "15152722", "md5sum": "92020f9a8ffa9995143cb87e55aa0992", "sha256sum": "7f15b081aded96370475d14e31a445c1a8c38745ae5443979250f67b34f98b1b", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmSCHLsACgkQeGxj8zDXy5L+CA/7B7pdtqt2l08ekUU5SZ0ro3cDoOEjT11TfLs0mB64h+lJBB1ZUICorPNWnF37wK5HF3/XuV9ngcfRKJXY6z1vLYKTMaSFECCB83wTvnEywm9XWGzfqJ0HUcLJD08BI4qaphh8AUdY3+HDv6bBJhsrnYabDi/ZQxufw1lQEywWDQi0KgiTMRUu1BKMSy47HyfM3HQ7irikpajSDDpsphfRT0GfG4AE8PbfeKQbOfMqfQYUq7qIB8DLRG5wpY5m+MLAY4clh9QibtfXKwSjPF5+B75ZKAhImaJp41zXVIk6pK6jsnJoVFlBcCrwf7Y4mQW1nb4cBNimfpSA8iopJJGABdhZLKs9AfE2iOzxPJA52CC/+bJynO7fWuM6E8Xz9qdESR86bIXWplNc1zKI8UH8xzhDS587VB3gDEVTDizASc0vmE2fdxva6qOjUgQbnboWcFG75LhDhjOx3n6Cobj0DcoqEmVMFDAyK8aH8QlcGzrMA0zHudRLSmxArc40OKYxIKfPVtv9Uz+/zqcOirojGQQ5cXKkarAf44H0vdPuedVi3mn6dQmpW4lcTaHWYdjLbgZpMvUD68s72GABC/bSQyrNFpspdIw8kP8yTRmnygt1caObm5pZf9oHwLgx6OsLNSwdMalEg8olACk2we4BDB/tj16DXosnfd6DRQTjDWk=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1686248263", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_x86_64", "ncnn_testing", "ncnn_x86_64_testing"]}