%FILENAME%
ollama-cuda-0.3.12-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.3.12-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
266546887

%ISIZE%
292183881

%MD5SUM%
389c8dccc0c0e5311b0e901993204710

%SHA256SUM%
4f7d820e2f7bcd70890b311a64418ee97d4572ede55248b30cc4be3b6795c713

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmb23HwACgkQwyIX9vE/8ZIvlhAAnCrc61D+JGIesViAfo4WmYZJnruHbMGaTI5eunpdbbk/mRWIafOcnkf5nmFafXxKYisjodgLdRXTLC811RQE5tydJuxG236IdwwjOQjG2C8DIcQV2pkH5jxpkCjwlz+sh/p5Xbalv3XJiWBUajctEy6ZT4NmN72/SsFF5CUJd7QtO9Te6o/jyRnVqCyGJZu6T8dJhymfdDuWf6RfSwnN6DepZZGvKTZmITyZ/jTWHkAkN7FEOWBzpuDnp59BZOTeVl27LiJ9oyrLOEjKtVH8VE3Q+mz9/NxyqBBsJERkrWFvgE48kqGgbnJ2/zqzROqwPU72lq+tzU/yRM6FwKi3dbubIwOg23cidRiH4Bf41kd2Ml4Mda49a+NItzVyRsAasb60WI4gLundgwKVosejbfUEhZOXYG11JXGpWZCjndetsp7F4aEVZLW/5bv3oM80FYhpbn76VUodlRXD4p9CagW6kyv1tEovcS0UfSCETts1/yCXl47x27yYIXQAOQqvA+5SfpUfNDlromcFn3Yl1WP+DLMOgJjoUXjwXhqE1BtWVwKNbh2Qb+URrK7vCxXhbiNcercU5BH7ZTx6LJ9mm/mFgSEezkKnPMhCAoMptQz+/edaaJhUXcjhRPQHNt8iy/rj5iUFj+cqK3IWvDKhoX7fNztXhfDW5+c7kxLWC5k=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1727422938

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

