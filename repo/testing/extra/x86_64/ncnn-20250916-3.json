{"filename": "ncnn-20250916-3-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20250916-3", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2939510", "isize": "10389850", "md5sum": "c039425cfd769f67a71142efa94ff8aa", "sha256sum": "9ecec3b479234f0850bd999c2557d72de0bae58edf8865c864fa30eb25a411fc", "pgpsig": "iQIzBAABCgAdFiEExdKm4O0tEcZrn6KjBjE5EQV91agFAmjlTL0ACgkQBjE5EQV91aiDQhAAiGo1LM02aGtYvnRqdcWPvxaJCZJMuFpubuFF9HUZ8Viy79qrs65Yi5Jv3mb3bPV50f69QI30Aug9SAJZEzJ1NGI0q1V4gDiAJhD+UY2dGHKSnF9bsUrebwpwKWqdKRAvSI8h/HrNekhUsxyflYeF4UY4RPijrBs/0oy5m2N9FjnCaxQRWRuLmt3a0XFutw6pDI3wcxu3fue9hr97rShfva5ugxJMUggkCbwYq8iJazIS+RMx5/tzrtgF2PQExrBCYu1OEcbEYVcf104bVsNw1/bZrwSeSYjY5oYVMi83kp12GIJSOL1lwqYmHUTSJZ4f2SSLLTOuVfr8qkeHiIGNYoPKDs1Dx+XK3tR08Ad4DICbVD4A8TBKoZZYYpp/7aFWK+TqwOBOdEbGHHp5a9yzC1e+Gt7lbeZP8Z/YdU+W1zEeoYtA1xk+S8qOOid/w0izEDz7tzPBHQtb+bOf/+6XZJysauIvfgOLEfnKMOTyLZPrtxNVvHIU4uzjerkrGUSnxe/BQbLXyJgbkfi1Ar38KkCwrfM2x8er8oMcoPexA5WQBVzKBbLJcV2e829hHUnTrDVT5S/PmgkFQn8FDo5jIhc9wyxc+/wzFmtq7GN6RYkm9EPw397pHjpvaEd3idNDaS90szufOVZSW+jNcYo0+030nwxDt+DwkxzwbE0nzlk=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1759857657", "packager": "George Hu <integral@archlinux.org>", "depends": ["vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}