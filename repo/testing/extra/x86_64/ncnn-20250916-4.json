{"filename": "ncnn-20250916-4-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20250916-4", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2941959", "isize": "10392186", "md5sum": "8b26e910aa8e484af61fb1f48213658b", "sha256sum": "ecf185307cd2948b901da024ab502cac088d593ad29c4d706fc0d4c331418777", "pgpsig": "iQIzBAABCgAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmkDJiAACgkQk7EdqkwZfj3bpxAArL66TR6BeF9NGX7KodN+H6IwM10nkel2Z6/VcPumQ0OX61eIGIYyE1dvBnvIWKPCF4S1aWkQOTP/VYkqhDwU8CPZBIS5CjK85Q5iYOEYtkLZFhBfpWjD8dxAKNiF77/pYA6K5E5aMnBZn2w8/R9KZRqt+3gDaLBH4MtttzAS47DLBFM7RdGiKHO0MyFXVRB+Q/bY1364iNxYGNqLaVJ0BMyxhJxFeSOKdFo+5obxHS7bNSAncWxVWRreOX5H9RqEuoBGIXtjOz4Pn55Y8/nOYIZORpsvhdmARO6fiuG0Y4qpOyCszd4esNvXFeKhsHm9C8krghS27/l0oLV2BOkwcHQSJ467rqlBS6lCp3K+aTcn44UTpuZ4bOiWuzQnoTCYpSoc7Qj5Xxk/+ar/rjsKUOUZht/dl235GMu3nzBNp6OULL31oGpp6UG1BkSXPBczUUZHD9CHo1QMpNC8LdoaHE96rDwSlht2WFyEMOf7bnz6HITFMqVYEQusu/CkqxRitkblDURZqh4V/VKFE99aVu6VJpmWm3KW4m7rUc0z5nAuUswy59aQJCulvuKuNb19EhmAlyre5iIgn1o5XRtpm2E8wydHnD48wG4UPf3y9y9EPoLleUOFTTigFV5W8NSTPsHGNtq7NE5fyOor15kDaWXva70vBXuE5WBuBS8mZcA=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1761813972", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}