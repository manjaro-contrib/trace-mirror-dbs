{"filename": "ncnn-20231027-1-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20231027-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3835319", "isize": "15416272", "md5sum": "84d73e1168f1280ab50d3591f61daa64", "sha256sum": "d34bb685098a902e09ef501e96ad0db1f7f44b48e51fca5d697aa6421087014a", "pgpsig": "iQIzBAABCAAdFiEEtZcfLFwQqaCMYAMPeGxj8zDXy5IFAmWQYgAACgkQeGxj8zDXy5KaOQ/+MtDqBa22RUSn8kXeMBI5jgGK41RUKZhdtfrTtZTKH3NMDC1vmdnWROscmxjvaRRrQWIAw1tbCL2Ihr1NieN4N5cGgn37ryZzpSVa5mccU0ExcydhkyXeRxNRZGwFnnvabGi6Uit4vGfuBr1BQoWDFzD2rueF96Z4CfBZszSz3Ej5e3TEGRSdpFOiBG2RaugPC+zgruJd/zFd1rZGuC7SNwSa77R+7gJnTL5x9I9QOSc6zGePrMc1elkvU+hpcQZlKWjQ6iRy+m5sIQSgfyBrZJ2agGXm0BDpJzWdBZjFsve/r3d3tPMJS1sQg7ZDYAgCpcPKGNP2hNDuPUUJ+GydgnzJtl9CjPKgjZiCTnwrXkRDS5E5dN3VeeKr6VGz9bwJTlS9fNb00lyPKvUmUPMBAm7djNL+pFq0sZltmZ8PRlPJHXZW8uYQ3EDZyQmxf7ebigoGZk4hz7piAX2zfq5y8C/p9jIaUwOlaE9QjDwMUJQdH8Z9vQPEMcag36GPUj/LvPqXLZ0e8fLZ5TqIQzxLmPgRoyrehE6KYqr5THWnABgpuiSQ9JmvRtOaXC0fymSadvV9CXy1rrc6+zyfVPc8YjNOY4701DGsHEgSoGOQd2c25MJAIFNa/XT+3H8XGMhAYaOhNGFH/2niCqIKM399ZVflOj5BW1IUpCVZsQhiB6E=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1703960986", "packager": "Felix Yan <felixonmars@archlinux.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_x86_64", "ncnn_testing", "ncnn_x86_64_testing"]}