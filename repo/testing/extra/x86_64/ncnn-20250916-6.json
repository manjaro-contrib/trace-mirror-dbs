{"filename": "ncnn-20250916-6-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20250916-6", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2941985", "isize": "10392185", "md5sum": "b3b7449321a6111d3000b4ecf36ad413", "sha256sum": "990080634eeaf182d53c9c916bf54a6acd489d37f085239f1dd1a4fa9f9fdd6f", "pgpsig": "iQIzBAABCgAdFiEEJipY7GxR9+o5Wy4t/cMEC5Ksp0gFAmk4rngACgkQ/cMEC5Ksp0hHdhAAvdeDIC6r/opqfWztKb4/GGCnMVFGOY+6PYrlgAKzzju4K0+ocjgHn3nMal3MlNzIsScGmf9spsesGyDqX2w6aeEVWDucASK7MiUCgkk2bf5cXQ4K0FmTNegLHT3YgpPQyCNDIHk7FZVlrOg//7AUqnaKLCg5hZb4BKJz+YEjyAOkUovOWgY8iziPyJjJX4Kl8CjlpsoZJnu2lvKWbKP9EcCXBZ9kZ9Icry6250/2NRbCKUJ22E6zXlwKC7sFYx4g3xWjqe/K9QpELx6XXmV8dIje1h6Pb/Rxao4SOe6nnQKSN2vAxXtaUO+WKFwAKDM/1YNV2alCWRIeVY0rsyHNsYgUE1znFZax0XdkfewMRqLCjlO/1W4V/vgEhnC9VjTQw0kuB15CBSzs+Q9ayLS9wcwE/bd+jURVXzkk4kbKInFD+MImTCmQtRFhNY9eszpbvshjvhLGwb/IpLGtn/QQWbYjqs/hIk9HrgySYo0kJhqgtB1ik0NYp7eyouLAQCJOSalVC+hyv9LR4WpcdHq9+AKm6BLP4kQSnOny4t6WcSnqxSM9xTSXbnEx6XPvSxP7che6CUe4QnbeOyCt9v/fXhYdBAwlynxaPjdY1bqg4nszDM3clQPW0yLWfDXrkDZ1c55RWxLzfCnzDSjPlsvHet7cuoAfryP+lJjl1VpZzjE=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1765322282", "packager": "Robin Candau <antiz@archlinux.org>", "depends": ["vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}