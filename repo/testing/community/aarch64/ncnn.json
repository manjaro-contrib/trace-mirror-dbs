{"filename": "ncnn-20230223-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20230223-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2456640", "isize": "11583587", "md5sum": "577da82775fa41409364092ae6b56d9d", "sha256sum": "b75a32737e0ba4b67f3d12eb26b96e758293d52a266f223566753ec227b3e599", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmQF8rcACgkQdxk/FSvb5qZx3xAAsz87tqRusGMw0yr/qdlc/+0ZZOPP7b479BYdUZM7um9r+0gc1iYbEITnbsZXLdIY+zk3kt271mK+NTgDRRcJqRkG7/Smlau16mtpgd/6pcdcLR3HPBrFP7UcStGV1ouzzzxUjHWA2xL6EzzDK92lbrS+q6yOfiLhJI4Iz8YqxtmEfCPJ8E6UmBZzF0OqA5y7XNFu3fpRrmo3k/Gmfq7pe5fAE96hV4v9jeq7wM1dDSgGpRGEGtJdXM0Y7R//cqfXyR8nF50XJoHC2B+OumeZvhuIgdWqok4Os6cyYTAIyKZsB1Gq8yX83B0MYbjpGqya08RAyBocui+X21GhGRvIrCpID0aTcMzXNmejWcVlT0zShkl1Lqx5ZuTWgcAM3nAt/guKKuSoKOmYaHJzQ0jMaUDwmWh04N3Ncj44q4s4ziaEAPf+JOPvFWn7hWUrUg1soAvibJqEngt5nCFhCXSXhxMgg4ijye0XF+wnXSbJnKzm48B4/o12H1/F+n7sstYJDvxo8taBY9vIhOIQdrh78b37Xg9DHEVdvsxFw5z6LTJ8UUoXjN7YCTHdVSTWTTCz0HIbgEWq0ot4tSzdXuQ7mdFYlwDBLSy4fyZ4AUirGfxct80rffqYptP8we+5d6gx3RQmA4P6GPTOJs4cSeZSElVVwUNvCyeL3HwQbmggbcc=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1678111176", "packager": "Arch Linux ARM Build System <builder+n1@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_testing", "ncnn_aarch64_testing"]}