{"filename": "ollama-cuda-0.1.36-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.36-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "428339256", "isize": "447982461", "md5sum": "058978ad111208b8cc89e4be3a030962", "sha256sum": "791361caa25630e28aead91ff888cb7789cc008dd9b83145064fb2ec7f87240a", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmY/VGoACgkQwyIX9vE/8ZKuOg//W18my+nmwnBP9RpcfAQp3ZIkQYqEnTsvK9nHT1W8JRmiYECBVfQBzf3lAbtwq/KrNjXpBpW4NkCi5CdRhlpVYJTMapJH2HejjcumvtpCLtAZA/mabd28hpAOTGiAvaLnXm7ucPLWYlDce48aeAsqQy5xJfcBPpLWRpC5SIop3Rb/Zh5giqj/By+vcAIUTpSHnojeqDy2BlBvVEzWCgssT/DLUbofgeuIbbPWFiKiCRdm7JI6Qh5XvkbIHx+6ZHhF1K2QoPGAueqPqG9dgnxJ0cgHf5sxtlk1DNUCc6QWc/3XSMoENz2NdkWY2G8qc5col+FzQ7gwft30qfWJxf3axyXCBm8sgFktsX+Sk71d8P3CrR8wnfziPyIKFDC8gX6JEgPvnrc0S/yb/WOGnQhLg7YYzUH7BZ7bXkqX1UVAaKmxJhVq647GAZqDkpPgzYZbA+FmcPhnAVpyaXsJpV0CvISYuw9WSVM2utW7r0Au6V9QbgY0W7t1H2JqPa97XbsKsPSHfSuAM3qV3zzMBNMSYJcN0w6v39FW+tcja2w022q7/lAtniPsNVV9fRQgv2kpaB3fd4fNSiicECTix7b/nszX0rlGSDATZ0wfvJ+bPpGhBa4szuVTVaukPO5oBARNiKDVcVsY7jRBFTY2kP4IT6X8AoKjaxQR9/2gf0WIFDY=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1715422340", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}