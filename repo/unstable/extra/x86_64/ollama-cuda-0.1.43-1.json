{"filename": "ollama-cuda-0.1.43-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.43-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "448020382", "isize": "467919842", "md5sum": "389fb26b0dfd582d9e322dbfa06e6aac", "sha256sum": "c1732c53d4a2c3ae10c7409527f76702630e2791ca9ecd4cf6c4360580670dd6", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZpboAACgkQwyIX9vE/8ZIaYQ//d2sWz/oedXkZkz/GhpnPkQFwz1KYjfj6NSR5arIC+jA4S5gHR4euDdxerIkMbN72jZYbiaWUWmfij4LX7BnDnrpQ8qE0hM+p4U2dNxX4Hkc9h05kiifj7oyDplFovXiP0ud49RoWZ26JV/9722RckP+YBY0YU3Qkbal+ddstc6YhGXQoxQvRyE3fU6l3j9WIhOMOC9TDnOAUvkqhQHoQ+mHqFC97bFajq1Ot4eUO9KdYxu4o0g9IVBlsWaUT3L2Jq3LXeDKjK0maAhdaZgd97sbtinmPdQObHhEEfoaFa6Qswsvr9Li8zTjZRFbfrS213R4naKWSWYi94Oc3ntcHZvujdiIk8FO9Kz7V/xyyz1LEyQyqh7g4xMr5OP+DuA+bCM/S3KfaBnJ5m9LqBoLWg16AjCx/YTi+EBjqG+aYO2zhCujD3pyrYch+M2g7CFTwsfeYPkF4kVBaRe2485QRkM/d+bGzldwmL3A5ukSgHh/sLXFnHrPVs9Km7qUErHSPsGMrnwd1XowhQOsU8FD0nSzNWJiWXQJT7annDR0UT3EuZcg/Zo+OMmMDGNWqnaURAwhe7FOGJgalRit8VG90WglIzgcTErisHy1MyMkO3pg7pLNxkhHyjU9xmLANDPzYhEnXHmp0062lKrlFQbH7gjxTlp9KkVHbVxQntiQyGsw=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1718177920", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}