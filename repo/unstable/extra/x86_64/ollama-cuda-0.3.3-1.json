{"filename": "ollama-cuda-0.3.3-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.3-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "596027575", "isize": "618866794", "md5sum": "7574ddf19b9ac4c804ccabb042437b0f", "sha256sum": "30f6eb71044dfd562bf09fb6452d586b7fa210b822981dd8dc091b9b65091d5e", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmatEhUACgkQwyIX9vE/8ZKQixAArgXpEk6jjIlqP24qoSGxgzvnnwloE+N/k4E5RMQO0WMZGcd9koDLPjpHAQBhvoLMBx3As+9kZ3AVLxRRZncaOv/SsocCr0r903EOqkg4Ip/KCMCxH7GQvCanPLKFtkcBbax29rYBU3HqQqw07NlmOpgguYbvuDrLVZeYP2JLMOTcTy0Yc2DUEaUBPa+slsKEQ5eGtNQB+ILR3R+tczvvndOrSjxrk1qun75md6u5qJoLhozoHRijFdVghFieD0v1VOPFGPnIapKF0T1zhRDuiLjWubjnfjCmrJtQ24l5Ui9+xnHFr/AKsuJv5KNJd2QlM3sTE2I34I1jM+DXu+ynOAm/6nbD6KM+mKYg9ex3BCWswb7UuIZH7GOOWBa3b2fNXQTVT40K8iSzlYixQxGnfFwFSaYyjP3TobTUR+vBIhr5WftpDOXp6FbSuqk4ZK+5k9b1+cIPZzDITZGEVBbcgts8Wxy+U5WOHxXiA3StaB/vraouWgaKWml+v4Z/HNn90RRmfm39GjUU9HYE3KNERSBIvxr4wH6Ntt45WRJM4KWKpLyhtuCJs+n4SosEnOZzEJ9d1uD6EH4RWbmjbJp7oH7lz9uEKcefZ/+x2yYerIjVhXGEPmy8z07gpyC9mFVHCYHHQph/Fsv7sV0PNZdsq72NCj6T+TSLdhjWLrUXhz4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1722598619", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}