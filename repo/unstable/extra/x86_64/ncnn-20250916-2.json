{"filename": "ncnn-20250916-2-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20250916-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2939630", "isize": "10389850", "md5sum": "75141fdaa2ffb1b96b7878f27efa30bb", "sha256sum": "e31a18bebd95334d3eed0283b436244cefc6a2b43d506dd37f1df1689b61978e", "pgpsig": "iQIzBAABCgAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmjQenwACgkQk7EdqkwZfj1S1xAAqjJLjwUKhKkoy7KayZjF2Xc4PAWxhzPk0cwxgm9R0frboMpaZ9un8o2b8udN03ytiJBObGFn9sghIfDvRiWD8zRhJHYajPOrOhrzBMEKQRorjkul+7EG2ziDU38uxq9T9F12nT25+laoA39zPiIgtTXbEN2Wl9wA5clJ/168Dw3w5RfwTY+B6Pol6Go0jPB9+bxdDHlPt9HHD1uzU5gVzZPpgMJNHUssy3ceJabJSXNLqPLdOmalAyK4lOAiC7Ww2DzQ4UrsJ2jkxdHu3wmgUZPF4B+bblRD3GbBV+dZfe7W4wNUavMRR5jGjOoQ/ofDGYwr4f5L4rkpwgBNwnM85N1P8nk1y1b+Ce4NinpO0H9urP7ceSv7Q1EPLSl6xOa2vSNxLRssQvaoC354QwQ8j/syicVllBJZnnkxiOaeE8+lH//ryDhYk9aZSsn32QJkiwyl4pfOsZKEbIUY+RAH83GiWBjHm683T7JEncAV3sNKFHrOFoIL7Txr6ESGjPxT1K8fZuXyV69CqwnjSKidib2lleKojGl+cr/Yu8mDx6RMoVSLdfIpxFMELa08Gk85J89/rJDev+p9jwaVoP0dyO7k6h+36yrigEl0mFyo6+jzouIwLtLUMILsdhvAy4YpYb2gyff3prOtPfqyiQN1QMFiHYO5CQoT9/EVms34urc=", "url": "https://github.com/Tencent/ncnn", "license": "BSD-3-Clause", "arch": "x86_64", "builddate": "1758493233", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader", "glslang"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "ninja", "protobuf", "vulkan-headers"]}