{"filename": "ollama-cuda-0.14.0-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.14.0-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "228304596", "isize": "1827699976", "md5sum": "9af2cf938871f5b9fdb767ad4fb733f8", "sha256sum": "e85e36cab48514bde4b98b976c77b94d2916b07537dd07b87339b99ffde9797d", "pgpsig": "iQIyBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmlni8AACgkQOeS4d+YuuRUgIQ/2NRmwdkythqyy7bZ/6Vgh/HyXRtEMKrmPA4sDX3oFpOCYh1dZX9CkhgsEveWQCOGD9GpyZ3+siwMWQos2AjQcMsJBR1e1XxVBT9iKv06Rimr/CLHMmlsZwHNbWTiTSQyBVG4nCDf7KUZEKqKVcHkTADkdmQVaFCJESD8rNmAMSH93xyql6J6POJSflqnWrQwCZWeTULd8CnveWihus0XfF8PNuPweW9U5PYmIYjGz+AdsN/mUEuHd/kClSU+8vkfeCbUAXbG0r+mgU4TXMmip2ydHaPk/poN6ltrmoI3+L6/AGCl26UrOe9gAfIqIEQrCC1bX98iuAD+cwSXvhXwzeUBI5l5D516oFxBSi71udmPiqgEu+Jfao+XRLPcxoEc+IicK64qPATF7ITMBzKpNRavuRGOd3Rah1Pp9WPF61gp6PnR0SKpbgrqNSkQUHKizdjfbHm4e6xN7+Cdc9Fo5apz6PwrQkExYDzByNhS0PdTkkFlVbQgygNvS4m8p96BDgiN1z+ZKAqWUJrRhUVEpWBImMn/Rcua/Z/xt9pOI4SASKlM8/mGn4Zs+lBhGtD/dvVzGWLMSC4+zJhrb8o18op2gsEjQ7HUboH4DZcIV9A/K8EBOpILccFjq55mIT/xiX17+1e0d6h+/BaPfCZK79MI5wv4DDX4GVLhoOi0hUg==", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1768392271", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}