%FILENAME%
ollama-cuda-0.2.8-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.2.8-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
596136338

%ISIZE%
618449066

%MD5SUM%
462f341e80cbdc3c3413a5dd8802e9e9

%SHA256SUM%
2d6205ff645ea1ffe635908da63645906645116cedc9d0d06f13d0655232d4ce

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmahLAEACgkQwyIX9vE/8ZLTghAAtft3nHMq0Yoq9DYnRcMeTypt7J1gmdUnzfkFnT9cBfmk6ryx9fVu091DuMhesSqqsMnThSACkf9I2qpC3nvEzJadK6xg3jkkB0VjhdwbXQo4LXiZVBYk79f8qQ4xVcxeIWMRCTleqNYRHgVDKKvlenbAPrTmHizZYSg5/YcWiu8PqChzXis6lhWrF1fz8Gm7Owt+k0/TXX/1OZ2kvKXWjCBBAjDHFPge1S9Yg3PRTCkekLo9kf8jrtXf9q/G+HlhIlJbX1MznZv4MARBq5YdCcABnaF+wle0wlavus0t3fe9xwLjRTKr4vGqCeLt8fqQyAprxy4MZq+2J4oBubUvSHM9PDBWErInp3oecwCCWo/94h31B4Z6PMjrp1k1xU9RzKDRowmtx745Tr59pVZ7oS5rLeWtgy7CpUNvF80SI1jSi6kMdCSjYM8LQfcLFUedsFxTHRHjG7XBZMdYAuUCx0Vz9Y4iGkAJHzk6bFWXY3c+wV8FL8+YU5u4oEQ8TwhQn3bjg1O1B6UusC0kL2dnRJ7+FwXf92Ccf55G4+blBKQO5H3tSw6LuP3oM+9laR6ZmjFy33oYi2M9Rq0SPm/IFkbfxlDrXt0T2Hie9aQHafTbQcohzC8gqegWCerSkj/NrcJvMZEq5yi7u2LguR46Z1g7RMKxe9lMcbbPzAVoHtU=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1721825995

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

