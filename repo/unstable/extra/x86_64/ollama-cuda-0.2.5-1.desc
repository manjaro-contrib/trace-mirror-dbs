%FILENAME%
ollama-cuda-0.2.5-1-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.2.5-1

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
549573114

%ISIZE%
571230210

%MD5SUM%
27d0d7763e6a51fe8fd5e7669f872cf8

%SHA256SUM%
43560ac484bacfc5f0c4669d9d20ac0a045976dcc575ace24dd85fd400e140ba

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmaVJGgACgkQwyIX9vE/8ZJGMRAAmSKmDQr8XMnaEodjzxkgMg9D4A8Ue7ZThLmPOAh8vmkyCSi9TQtjccI2wgiLadHzT5+X7lqmhN9kR6VemRaSZz+PpMfe9EKGByNsHesPZ7Ua+XTKQ5KmvVpxWqtwkxJDdqzMOERdGAJ+rhvRJgQ5xQrOvZa1ykcsunSy+QmncIUul3LAxUdMJk1J5v6RN9k8J6IITBkJfxVpSe+vu43SI1E5aGoaxshL4LoS8fSGmn+eLbDHnIofgaKOlqRR1aBWVz/9K59hXKW2/KPCyRK+8uz/XMSeZNk3/vLALEn0XzVtgtq7Wd7X7pNKYUdNKjvALQRH1kUdk1B3FkjsymoEya0Cyg0e0MQd9FjwZrDfSAKeKOp3n3LP6KHeL85dIFeDF2MYoQTJrSLdyhSVfj6TfpMrh+a513u1DI5b7s/WxThW5Kqim/RqyRhlcW7TcWZXWmScEVwX2rL95S3UjhAvGNU3gIVUnjxLdUAni7npPGCft0Shc4LffWRCYrpkyldWUb5KbSFxW7bNRCUBu3kZem6/+Ys9c6myW7RXLZm3zT5/vU5dDXSMHqGXe0UwLUIWHK4oQ6sBcMX0OJo0F5kxZYNgjvYz0yaI+5rp+2fi8MJM9N2Si1kTFwWQMyUqqqQOU02sVajeAd8sUOUklwqq8LHJBYVMyrCHfPawGnn7Qyc=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1721035592

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

