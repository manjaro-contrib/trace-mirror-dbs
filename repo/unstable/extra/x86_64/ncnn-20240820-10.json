{"filename": "ncnn-20240820-10-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240820-10", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2931889", "isize": "11987046", "md5sum": "b0d1dfe46c255f21e8ae52cfca2423c3", "sha256sum": "2dbbed2249f74740d224da3943635f96684b6f20977b6ef7c8893fedce8296b4", "pgpsig": "iQIzBAABCAAdFiEEJipY7GxR9+o5Wy4t/cMEC5Ksp0gFAmeGTJUACgkQ/cMEC5Ksp0gp/xAAtqBX9aLBK7t+Dxx0hACeSi2P7eQoeNQIv306I0fky9KJvHAa+8ILXtHnLejcf3BqA9CP7tN54Ekjl1baSYSkBhsPVe8Jb1JkccIXtWCinTi1pf+VZ+LpIcTS6o+2QOdMy934g9KmoDvbaYbvTXkRj1JA0INgr4r0IayAJzHEoeyVRp9pGVxATfjAxPeStB7u/oUehWU2NcqkYe2kl24DSi2sSWRry131oimYSpI2XgLz/C+WsMMoxVqbRwAGQpCU2nIjBoRswyIaZmifsgzvERX4QiEptMCfhpL6zDUoW3iqC77Eeno8sd/p6GBFo//nzH3ZWn2zSJi98jPbRDdDYwQDNZk6GWlwQsR6EVG1Xo3j5Rufv28pI+baXgOpVJs7CHX3vxfLMUk6VCqo2uA1tmFHO7x8uUrWb+XeTY4owKkZXk/36K72MY5bKoUVGHTKCsydws7NfiSL6XnvDnskKzNrDqcQBWnVgmMLSeNLeDpeJYRBMQoWPpR05I0B0ji+8cOucJ7kaCUnpfShhRmSbCTmpWM5dMtOJTuo7mxvGMfi7AQAw/PjNne8SrvexLsOw/RCZTDls7/Fbt66Cw9+wgC0IG6Q+6JeWIIc10HmGVxXnjVJK/wxp0w13KkAxIRsD+0OoidY9BaUBS0y6sMJhUSBgFNQrmOUXxG7eOUnHns=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1736854558", "packager": "Robin Candau <antiz@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}