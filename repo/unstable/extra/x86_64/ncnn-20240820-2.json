{"filename": "ncnn-20240820-2-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20240820-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2913525", "isize": "11940381", "md5sum": "a5c6798f269b80adc49b70e8ad68a67b", "sha256sum": "068c888dc55bce590b57f0e78ae3cb3344b1d2092d1b592077e0c8d72d19c2d9", "pgpsig": "iQIzBAABCAAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmbezmkACgkQk7EdqkwZfj1wLBAAz6qsIzzOEV6FsLxsuVQM1vPm6fMNWiXSWyOTkOibpNyBWxNRIz8sOpLK/A84on3XQ5iwib42v8B5qxFIGW5MmbRBzzCuC1RA8627N5u9m8/RUkgErPyIiGl8EKd2IeQaQD4ee2oxSJX52kk19pHHNi63rzCGWNehKcij7rGUlQkPZJbwHxogIK6TRIaklpZm5r5bSfEgf04IWXpoNvneQXnQgvEhFggWiUHgvEIOeJs0PVLebUpt1zOPceu49lbMDZ4bV+5anuiWHx5flIJdzF5e4O/qFBGQy1N1CjqCuTPyjQamFM5xvFNIv8VrHTK2dfAfXApmeRlaDcb6hQX0E6XHJLAfVK8Lddvvo9OGGXkC6D4ChkGMC/rKtfFWgxCHBWxjb0cKzIcrr7p8fnghT0fIQO3o2TFVDkLdGXroq/OheNEqpQUKn3tuia4syK4WAiS4aDELw7/SttQIeREbUuwzu5eLaIwui1fHp89MZsmhHabWsDR/YfWz0dZSywjUt4mDwCnLcllGtVXafB5Q5hSR2XK0dxIhYxMTboVpRls8FKoQCn6aM9abyuyuDkfm2/OriFdwCFT2Xfu2QTFmpW11E4Lq+u+6o9vZ87kmie3ezuglYFVU+RO3pIRAJpha1lNeleqcaybCdP9OyiDO2t9rqiFESpGCYl42GmPr4BQ=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1725877789", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}