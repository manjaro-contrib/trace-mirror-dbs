{"filename": "ollama-rocm-0.3.11-1-x86_64.pkg.tar.zst", "name": "ollama-rocm", "base": "ollama", "version": "0.3.11-1", "desc": "Create, run and share large language models (LLMs) with ROCm", "csize": "209627696", "isize": "230745417", "md5sum": "9287f14fb58c646a48e0b34ae4517850", "sha256sum": "99c51188d412529da130281a9394cfb73f0e6a2ba5de8fea1fd94e27b0461d03", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbwUnsACgkQwyIX9vE/8ZKjHBAAjKjayV5GdhMDR32BuTmT8FzZBKIVLJyPhqh4tePXvQK50CoxlmCEBGcZEZqzgjLHY4ymWS6JFdaQkK4QlrTcUZrgsHvoKfFrs1Nl+6t0Or2MQqt1Wo/Fss+KvEq+qKTKfHnSU42m/sC4EKJEP4o11cWpESMP1Larbc5tZEQDYBVmF4ojdZ/86OqcKDjPrWkEALbmjpJgF+KRtSqj+CO7WQD7O3RKItV0UE7mBsSTiE7swBUONntj4SBLCVx2LXe6pffqdkGh/RRwxTTgBQw9qYya0RA2z4A4llOwctrtl9pTqXcMsrEn+doDTszzzvR2tq2YNGF7aTYSL+GltJVotSOz+NzjTyDpCWpKGVpGuD2Z8PTEzgBF2zIkUH5MIZ0yLyObHDRt2DZSspubPtQdAlKH0YBk69j+RBYE8+3nsgZH/pFH2rVshsvnvwgsvG39t4A/yA/rlJth5GUHVDeLzlPWt0yftnWZRxnV3aCTZEHPzOFJfct5VX8K4kKvrugWRzRO5t/pHuJELbVTHN096lhVx756/SlS8cuutiK9bI6T5eMDQj0FarMLWggl2aH55oa8mpzxeB5NxkvvIQWqjwyGdCg7YyCHwPxLB8FisT3RHOzkghGKDlCyNO/UsT2kJ53dxc6zl5RVxJ1CNRlnscSybUuZ0CdfiV0LoTyCFP0=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1727001857", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "depends": ["hipblas"], "optdepends": "rocm-smi-lib: monitor GPU usage with rocm-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}