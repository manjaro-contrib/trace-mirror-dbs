{"filename": "ollama-cuda-0.3.8-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.8-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "235227684", "isize": "259992522", "md5sum": "67ad46604e8fbacd96c86f21520f81e4", "sha256sum": "255d95ec9f3dcea14192af181b1a8b236b291be6b729bf2842fb828779c889e7", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbPnaQACgkQwyIX9vE/8ZIMXxAAsqVHnmRWr1aKC0xfZ6HJ3PQqlb3MUEVKnYQQX2LhoT+7GvPIWlFZGkqv2ZOjScuUx3140s1EWuegIiZvioWz10PL/x4ge45pnrMVUte5EUIEO7w27Z9LFufed0nnRjU3tJlIOUSMKNmcUvoC/vh6l+Q4ngxsfVxx6JVA0j/EEcdUKulCnpx5uePYS62SiNG5h2bi7Qe726aup4LsZtHzfE6dW8V9+zdBQ55ZHhvy93jb6gycRGJiiX+JzpDOYiyv97pZBol87JE5EWuVRgcUXAe7Vo+2swAnb5y+WKoyfr9/NfIptQcNzErjvLrpVRLWRcioaC8iu+R/Xo52MTqb9VPxKhiwg4VJAbkEKZ+ZKSuK8Q89qQMVikmwd+BqUTILGZnh7hoFtRoLus2cwL74p6ptAIK1dsMYeXsHu4Q40GqkLeg5Qz09BBPvM7tjXBp3XAWiYrTs2ZXNMfu1VOE/uwkS3gixAnj3twz7hkd+c3qOstyD8ho0wcxBpyBNzp4aucMlGLA66Aecu/sEMawZm+SYZIHP2MI8BnBgKFtkJF1QvkelgazvLG43BKxVONpjntS6+fCzSXT440NUTWdn2mzvnqufHbD2ZGus4qwquwwRvvNJzHplcDTV00CC/AJKiwivxGJ7bkflKHMTMNtLTqiaZxCinlWj/0o9w/1/0tw=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1724871344", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}