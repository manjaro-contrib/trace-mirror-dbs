%FILENAME%
ollama-cuda-0.3.12-2-x86_64.pkg.tar.zst

%NAME%
ollama-cuda

%BASE%
ollama

%VERSION%
0.3.12-2

%DESC%
Create, run and share large language models (LLMs) with CUDA

%CSIZE%
266248115

%ISIZE%
292189055

%MD5SUM%
a3ed8c248509fa5e6ec3171565ad5035

%SHA256SUM%
d2fd4655f2566f81dadbb996328e88990e42d49d0fd9fcfbafdddb1d87c6ad8a

%PGPSIG%
iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmcbxMQACgkQwyIX9vE/8ZLQvBAAgl2HCvd+L4KUjYTXioeIAuo1jRw2jtrZxrwmKjRBUBWGYH6yQxx7ZdC6uRAgZ9uHu1gsc8tYAGtKGF8giS98PtrtzdqXwcK2999fsehq2Y/yussv/qv7KQPzthveJtU9zDYUmHjSC1TqdCfRKTnC4WGKeLkOeUU0/AgGoIqwkVFJl1w3x+WjA7QLdyJthwgFmtggiPzZq+bbJMsR7u3ekvstjjOPG7KXCsamI9aFp8Ca0M97bcpxJsbziBBGvRulPiFu/C5l3AQpjN6lbxsczggtaOZeduPZ0ARqJsNXmk1kOqWDctJUGVVVTFPCfVtUJFsf7p1b8RAOxVl7nKuFlWp0RKNXtJ3sPzDA/JhlRt8wQbWQf6eZYN/CjUiM9jbm1fdkr+68eOrDVa56RgbP3mCAYmQv7ABoysdKar5/iis0OiAEKh/kFwQDZm+pt1Zic/qUn/2RrJZpwnz7WlfFJ+txLvkTdrWuZLf/pARjhJ4siTlNLsWb4Z44bUb01VREEmSfZrrMw7NyMnTy4iMbUASPLsIy5MCq4ygAusGL20td/b/YGHMKWuKRSMTBMyLQmvvbdteSfbFdIS33gqSE+ObzjKlhK3u5H3UqY9/38Xr4lKJpky5+Lhh5dr7BdJvVCyM5Q3GFj6b0P4ar3g1qMpExLqNVhLA4DZESWcJqzIw=

%URL%
https://github.com/ollama/ollama

%LICENSE%
MIT

%ARCH%
x86_64

%BUILDDATE%
1729857921

%PACKAGER%
Alexander F. RÃ¸dseth <xyproto@archlinux.org>

%CONFLICTS%
ollama

%PROVIDES%
ollama

%OPTDEPENDS%
nvidia-utils: monitor GPU usage with nvidia-smi

%MAKEDEPENDS%
clblast
cmake
cuda
git
go
rocm-hip-sdk
rocm-opencl-sdk

