{"filename": "ollama-cuda-0.1.38-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.38-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "428343490", "isize": "447994749", "md5sum": "a2623d237525d911f90e9d05fecce4e7", "sha256sum": "7ed078ccbef4eb8a3507fcf9c38629ed6957d6025ac6a9c5ca7caa341b5520b4", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZGioIACgkQwyIX9vE/8ZKkxg//WHE855sxLgMTA468Ho6ctq96pK4QTgFQTFQe7qhh3okEpaLLB/otU+FwNxxiuwRIlLm2Ko+u1vLvNvnmckTzxyy1GP0G/JOLGiWEiiaJgujSL55wvYKBQ7DltwlUU30WN6XlMdli4hG0/HX2QjI1FEHfn5+H3SQP0bVWKhFkw/p9qO2puhQSYThGv5X3RAS4KjFPA54mfT/7j1pUgEdvSQHgrkgVHZVeoZGmv9d24o+Erz1HXv7zKQzlhnV888o9MqjXtfUXGTdSiD/TJJzHRm+iTYAPcsBqbsMwAePFM1sDI15o7H9Vv8Pn/B7ABDxT6OmcRE/VmvrnHrJFORW9oXq7ghYxKmTkG6daHeHnULxOPBPsPt8R7V3U4rNA545VZCBcGnXDP0XQfsmUdpC6zxYlEiEGpxSIF9YfnBmbv+Hov85PzMbTQ/bEftLCZHz0JcnLWjq4yKlJhVjclhZ77Dmvk4vSY9XmBafFkN/8VwJCdd3HCvRIw8QWI1mGlBS36YLh7qUz7gzHc2JyzO3/G3FrZtXLwNXnAeY/AuRMcWIGWrSsT38y3UaFd6QV891/BmmScynyXqxAY+5FnwKG9mIEeXxM49UZg9Lx+oQlZtdPau7TnibhKlyiOSXCrpGQ3zJmQapd7Qot8vvDB4Q/FrqKmgQPzmCTFyX64b/6p+U=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1715896151", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}