{"filename": "ollama-cuda-0.3.9-2-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.9-2", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "235143358", "isize": "260005713", "md5sum": "07bbe2516dee96c86edab77193f44ab4", "sha256sum": "2463c0aad46f33d3dd1570d1b3bb878b3449ab0256500becd0a89fa42856c196", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmbYWuwACgkQwyIX9vE/8ZJPog//X0dBa/X9nI6kzIg1o7HZicb2PqJiwCOpF1SPAq3fiwNrpig6rgigcNl0L+c8Sa94NTYDXwYwryKSZiV/LDhOOj2fZgx4+ZMPjKGGk/A/gogcE2eXo8VInLqUtvcl9sW4hjcT3pWNBUChyA3KjGayDXfhD5B18fqTb8Pc0uj3hfztZCauieTv3Fv4fx4GDCl9pGByXdxMyO07Ieiwa2FaYM+Vj4P4dYzLI7JgqiGy5+3grKzklkXjic79wRGtC4omnqfIBQ1U6/lyDrtlvl5xQn2oliMFU+IeMc9zG/2Z4ihHnvvsSK/RAa5hzqibOceh/hCiHA1pzIjh/kum/ImhNMlaQlMUU4t3i+81YR7SeUZVjsodZYs1kygQKIpa/IEa8yFZ5I88/WYagHdWO3H3/R5H46s712xOiFx7+HIe2nL4F6x3v0hORFTA6mfNmj30zyY6syzcl+XndfHE5tiMruULHqPhKMPaAgpwQYPTMCeFvUfjj8XVmkJbmeICjSs4YTMBzSTjMrYwidpm+hkPWMtky4v4R4H5FhfNlpmqnZCB32aARxYFVqhu92X6FWw8HKWuSlsoeOG6i11CgsyIoBolpg53BBpPaOzYekCiatb633bs7481PfBSbFVFAfPNVxwhYTyKIYmttLw9zxld/O/9voKG8e8KGZU3Tuoxsmk=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1725439759", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}