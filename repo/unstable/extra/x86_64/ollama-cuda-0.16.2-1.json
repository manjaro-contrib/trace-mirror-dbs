{"filename": "ollama-cuda-0.16.2-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.16.2-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "233295267", "isize": "1850543296", "md5sum": "6a30c59630c33c0f78cd92354946d3de", "sha256sum": "91ff1f26a51bc880498084649025f556f6451fad31354701a0497b20f34ef975", "pgpsig": "iQIzBAABCgAdFiEEj8FaBklQqZ3RvRTdOeS4d+YuuRUFAmmUHDQACgkQOeS4d+YuuRVT5xAAqxPklte/CldzBcu2OGNyfqg2TNStR1lcnQ1KSPfqos1Uiur6B7l+j+3Ko2g1+nNHPqeiyjOJhl0ELkFGlEm99vkwsYmLiroqObWvyXcRdzvVLPB+L/kj1OFpBqb2e/BV/eYyjzX5UhHaPYfbg3Tr9mGUaTagZ/colRaXZDA1UGM9jsgeuRIwiAy68fbaPsOd2WPD16TSfEO+gMI4JTSaZwqhFK4HQR2isbWkwvSw/eDQRfd/YVgn697j1fe2ETsVd3hCLJ4+INf4/gIiVaaUHrKkr0LYvVB34FjGm97VtUs+SLwylx76+FAUv7vkKSFm8+i7sH8/HjBcMUgGwbTjBpBXewqrFnwIEr/EwAwp/zGpphBjmfWFNmJmSe8xMi9imZbiltteqvstdKzjLpFlaIc6TeNbRoEUQjAKG//I6ZeB9rSNFS6DjUgczw2HoWTIMVOl0mEFnchqg4RzLOfGs777ex08Vroq4IsLxXPZm4ZWlk4QA0nE2xfCqQJXzyO3n69N0WH/pGpk8sLyNgsdTKapu5gwNPM5pPtPggOs9/2zhSB1/0UeCXljyFeo/ZGhRd3e1a+h3ajKaW3uNC/k3ZTCQiys3aSHNICJ2WeCAl1cR7dJQLrGwzd4bGQ+EqVyNAdjm9szUytAEh+losQiA0uHYSE9m/7vOtxzdbxvzt4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1771312802", "packager": "Sven-Hendrik Haase <svenstaro@archlinux.org>", "depends": ["gcc-libs", "glibc", "ollama", "cuda"], "makedepends": ["cmake", "ninja", "git", "go", "rocm-toolchain", "hipblas", "cuda", "clblast", "vulkan-headers", "vulkan-icd-loader", "shaderc"]}