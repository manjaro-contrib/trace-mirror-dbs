{"filename": "ollama-cuda-0.1.45-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.45-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "498690357", "isize": "519607586", "md5sum": "7f1449bb51697f9dc9fe9463705a3a44", "sha256sum": "f30d545953ef9f7a4b33c703916ec237585983dbd6dffe15e59175cc6437a476", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZ18eUACgkQwyIX9vE/8ZIlFBAAow7Ij0KCNPKUGpXpy7BFKqK6AhgwhYazUkw1xOpFRAOSyuNysyl6X/1RI+NrvLB+MlDlWFAAos7+OQBk6keUtR3EPhbhFIr1N/ZnA19Kl2FGhJzck2htQPA1lQv4IuR0QGTEhR4nb5nWoW6T399u/eiqKejtKXzPX0elNUFXzDAkeQ3/U9mnW8sYEY9Xhmy+37hJfRRTu6R6Cbaxu4nnDtkNIobUEiaL1U1YFP4Nk9aXGmIZuy2fD/DI/3p31THLfsTe1kfE1wMRlb2d/MKn9GGfabxk4X4q8Dj/H3xgLTqyN9H2OVI2UsP39k1aE5N/GcG0bI63CXWFI/UsWXSaNxjQxWr76skAbb4cPFPQc3b/uhbl1W007UmEeIGwPuQO5lr4Tg5l2uK5Tjk5pJeHAL2go2f+/0BhQEBnBnk52KLCMflIOFOW9M/xkz5fvnYcAFY7e/nY+iTn3MWP6TkOC+j44QZuzpNUfnDUCjPPTz2dqsPDDky8kaBVOYFC8tRrdC+VTBlzxMB+JVIVgUt8lqU3BsBXgWZHx235Xx/c4NXgM/ki5818Tl8diYgYBfqlUE2+C9NlUKY/tI5F2/QRq88JcB54ulBaWjvrZgJ6dLV1V0C/NpQXe+deDjUBh6i0NaS+fvasW8SaKJPcA5oLx6Ff2OWqUc5737mDiW6BAB4=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1718976806", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}