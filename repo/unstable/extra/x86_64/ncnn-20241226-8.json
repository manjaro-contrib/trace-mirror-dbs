{"filename": "ncnn-20241226-8-x86_64.pkg.tar.zst", "name": "ncnn", "base": "ncnn", "version": "20241226-8", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "3085958", "isize": "12237238", "md5sum": "4c808e4631e84e1c350e4008af52a178", "sha256sum": "45c7f6b90bb50ca752c7bb838514d4656d24729b7f887d565dd3270b46079cd1", "pgpsig": "iQIzBAABCgAdFiEE8AuW0VIoAT/8nJ0Dk7EdqkwZfj0FAmgs5MgACgkQk7EdqkwZfj2qaRAAtRxzHj6dgjK2wV+ZBSqSiqZl5ReYWilvUY5e3+3lTWu9jPAOsEkgo72jE2c3kCKVfuwkr9IyOSLpMKbnD39TuFTNZ96HoNN2qE5XJ7+mykC7KZR6GnwaE7poZMklchFeyIHDqHHP9tM4PdRERpXIb1Yz4vTapAR3qz+yrLHTIxdnxfy8jpBOUIOIjpeLZ/mMkbRP3UbpKrlb0ELUcowIfmELZvy79UqUp21xbAmyzMNWieCbp9b1Jm6d7RV0cjI4CcfWx2C2pKfu3RSsKozpcvM6I7LZZuprJ2J/coAggJ0cFL1ezCFZ8I4ME5gJdeEu7hNbsBhGo2tXRK4vXK/q+SqP3kTvKLFrJZzSramHQ/FkARk9USkTytBFZJCuizEroHOkMU6Yv82F0dw7an5lxJYR2+uyBvdKcuszVTZ1cV6G+dUR3i83bSYKReXY1DSqKXloNlRaWbAuJBf7QcwjpkMQ7zMzctCGnOgSILQWv2fwB2rxhVdkM/hEp6XjIWHku7wTafbCODKUneyuF0QAOBPdEkk7yCJCkNj/te/mZaucMhzvAB4ieD1KQHhmfXw1rYbk/Te1Mja1xk6iUj5xmSKINxnvgcRNQfuQ7yXzkgSTjMjTtaj50QYXHcSZCvyaNQFdNdv50Y19KmTrean6mnrijNsauR1aTgcFaLZH4Y4=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "x86_64", "builddate": "1747772462", "packager": "Christian Heusel <gromit@archlinux.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}