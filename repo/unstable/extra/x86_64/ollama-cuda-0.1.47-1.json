{"filename": "ollama-cuda-0.1.47-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.1.47-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "498583482", "isize": "519730530", "md5sum": "2dc33c35b9df59462f87b7076e2b179c", "sha256sum": "798e854e10bc60ce32be75a45622081994f3a2e375bc9affb886ac5485785886", "pgpsig": "iQIzBAABCgAdFiEEipvFgZxU/rPcKptIwyIX9vE/8ZIFAmZ9V3UACgkQwyIX9vE/8ZKCLRAArAngLDuTYtGdE//28ukmZtKxumxY85BJV8rtQ1jejYcVTQ7AW8Goc8Kg5B0u1uO0QLd+ZJ9qBH1QAgIAK3KzDUQ+MtUQqZbwqAJQEvd4wyWRS4fr3WYw8XbpgXccS8ipIQmloxJjCmKZomNI7znou7Hdlq/C0RerPOClXOQmVZLTBVZBoujq5eg15yS+ddE3uA8b4JT4kyEWwM1ULVbcDZvFpP9UYZ5lhK2kLtHceYwABg6qUObLUXzBjR5xA3GSaHHFS3WgEze+MmAwunHtGpCkM1VwtKNUp8e6zyvGiO2BZ2Glc46RvykX0m82la25eVNrQW+iVLvJmtVzjd7KvvRIu6oba/mPIby3nSrphPhnpSvBRz7MChy3Wo6tO2DsfS9XStceoIw/L0/DUeWE0l+hy0dVKAdAPihlT0Q7up567qHbNaXOFUOR9XRkEB3V+oa8lcdC7yn64zwttcNKU5pxrFRZxOIBzeJDxBZ/kzFixcxzgjL2JlrFVt0M17+UrDPFAcUyMk/7FkkZbVCti5Ddk2R6AFLt8pYQswyOFVAcpm92rYHD4rTQ6JEUKstw301nHcs5A4O35m2ykuu88QD2OfK1bRK4ZNKDAx9SkittO8wra46dip52Qd18y8I13s/DCImhJyJDKT2/akWrYqZ0aPqovFeuKg4ewIOyXpE=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1719482080", "packager": "Alexander F. R\u00f8dseth <xyproto@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}