{"filename": "ollama-cuda-0.3.0-1-x86_64.pkg.tar.zst", "name": "ollama-cuda", "base": "ollama", "version": "0.3.0-1", "desc": "Create, run and share large language models (LLMs) with CUDA", "csize": "596144944", "isize": "618444970", "md5sum": "2f8bffe9840fea93f83eedc234437ba1", "sha256sum": "ece168904acdf3e471923ed2b354abda5b9daf641952c1308c64b5892c83e9d4", "pgpsig": "iQIzBAABCgAdFiEELjbYYgIhSC/EXLfyqRdkdZMmtEAFAmakpywACgkQqRdkdZMmtEBbcQ/6AsAUkDcXjAJr//ngLhedlrrEwNyzN3a2DDOse5dSvFP3vfCBbOzRRaArP1sNZU9s1seDhmOGUMvhC4M1HUK9fsI2keEgusYm3dhIiKPbp/Oh2qRIm9AZ3OHpqP6tLRrYIxqiHklryX3QSXhuWavOd+129zEJHNSHtZC7Lhfp4IKbMTAEiHmFU62x13YoMviwPR7ymSPstgRKXD6ZtfcUPr6KJZwiinXlDILxYOwzK2B6rdKMw1afFI8k/Bo9hab4ERrxMJ2YYBQKdjlC2rPqLd8iXgstLX2wig23BGSFBIT00DEhWqg8lxOv0IMPKvvwVjXu1+9c6/KmP+IcK4HS0lDoJXcC1C8NiP52YYzSe/mthF7Lw/MbdOqcKayX15nZ8xUymNWi5It/YJ+5WH8nQf0P6yyH4FFP0UsQwSn1U+/lQnx4dmiseCf61pIOfIE9A0nfijtODelbwsACCmhztn41fnio8amPTgz4vnAYyuAyb/+bcckyBPH3EEfmCgKUCjUmST0lyzH8T6PcIm/YKQtYHBlHNYxMo1yiF17KF0LckPqWaQ+So5oEZk40iqg8GIoEWeyr9pVKaK05Vn5CNdSeFjDcwOBNlqnKCUo2HCJxONfsA4Bi3ZbcwD4L6TEjtM2jy7COpcMfSgCXhACSExI1SBmb31xSGtuTJR3QMMQ=", "url": "https://github.com/ollama/ollama", "license": "MIT", "arch": "x86_64", "builddate": "1722061735", "packager": "Lukas Fleischer <lfleischer@archlinux.org>", "conflicts": "ollama", "provides": ["ollama"], "optdepends": "nvidia-utils: monitor GPU usage with nvidia-smi", "makedepends": ["clblast", "cmake", "cuda", "git", "go", "rocm-hip-sdk", "rocm-opencl-sdk"]}