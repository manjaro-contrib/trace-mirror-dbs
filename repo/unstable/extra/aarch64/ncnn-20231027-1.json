{"filename": "ncnn-20231027-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20231027-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2608284", "isize": "11720392", "md5sum": "5c430c656ea96c10d9eefe58849b99c5", "sha256sum": "b9f0cac7135857d73cd3d561ba1a6e8c1f3e7c4a4c5733ca5b575fc51390b092", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmWQahoACgkQdxk/FSvb5qahGhAAnx3tOiJofXYiXui+gAA4P2pe7ZJTfzHIBeg5VwNT34RQd7psOKrBvk4TbHP9Cu2/DteQOpSmxY8zM5W4rB67pCCcjB82+Ezk0vgXOooTIr3Y9zjWq0OV5PQ2oTQOKnWlxdeTXJ6LjsdUQdfYo5BF381EfAV/XixMkneHkJ6cOc5LmPRPL6cKLwcdaxq7PF5nNs9U+GFMfByT25E3pYhDWtmqcC9Ydzer96sScDDdiCyX/D+gBmsjAXN4u/XGtUNkjrZd281TVc4qmIfdz22fZIrIrva39lfq6tqhgdpAj5x9wAWupHM6mWCEhn3SPQNGUsc43uAuoZC2jJ19vrp0g+NP4hHjAmPb4i2S+IHoVRrW10n1+tLZ0l/JSRhRkN2wsk+y+DjfvBtVUKkTk/WiEb8GSJMmNj7vPQpb8xC01iopsT1aQsvWuhu2ki1mpVudXW/es31UoNmPmQqxJXhBdxTr7cKaWfFJQ30pjk/5aEjnojoWqnjKhDXzriMUEcOeWaIzylv2RPY3RetXDw4+dK8dLroutOcjJghmEms48j+NGdYWW0Dq6xymtO5kVMGQsPP+OKdpxCZVKYdmLbWZk0R7Kdv2bDSrauqHhBkkctzSPbVNWNxFtNXL1sXX4tCXCQeGLpCmxkwDxnhSU/aeUWjCPVDXqjpcH5HEhK3wsQA=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1703963018", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_unstable", "ncnn_aarch64_unstable"]}