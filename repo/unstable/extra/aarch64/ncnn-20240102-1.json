{"filename": "ncnn-20240102-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20240102-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2648936", "isize": "11912441", "md5sum": "2806d052043b1eb66d7b8dc0f87ff50d", "sha256sum": "0bcb699041af3c6dea6eef5b335906fe28231544ec1c23b010a42c396a53b67b", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmWdBYcACgkQdxk/FSvb5qaT2BAAwprSt6D1GV6VyjeF64WSQ14xfs2s1d+HoLdJhADLwklyV601dbmC6XWlNdBNwim3sQdUK4Bf2B0O5+RxSHlNR3/HNQ69fYIFkl4BoLjcvhF3CponuWKo++nXdrlmKJEzW4i/JsEF5+bkeh7+rzdJm1WO6XySUIma5pn4gB5FLbiO+cs2V0gq2EafnX6KY8fkpZp8K7tGCA1alxeiSGrmk7qiM6MhB3Dk0LtntFkeE8+6luzynQZ857xb7tBlYsBPzhUiA38xKDOnVyyYQYPRWwgcTy/ng9/+I7EMGa4GK5Vr7gbBLRryaAicoulyk5Sf0D11OmSuddIZvHBjqKsgnpJci1jueVnfQHfW0XKx5QRl/X3RU0oDx3QrMFY5uKMXLDYP50kdE2rgZ11AaNtdvFhPz1zU648o8hch6+5ofuM8IHZsRYo2SbHO6RWtV/plVCrWbTm5UB73W2msaJhaxuxTVs2qcWHjZfsyF4ruF28iIcc/DjvT9zppC+JwzU6a2fgzoKbulkG6OsVEbfweVaAkGDGKw3ZoKp85GelNCpNk4ykHWmCsTf62DPzo59Y0ZGu9w65SzD2PcjWD2UYNxgwsZgs7AlWvjPIMT4GeUS5ImhU/zSfLpAXC+h+LGQ1l3j8QXmiEeTjJz+3ln6UgMFQ6N7VaRZARspIpcXDyM28=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1704789242", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_unstable", "ncnn_aarch64_unstable"]}