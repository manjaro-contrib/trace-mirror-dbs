{"filename": "ncnn-20240410-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20240410-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "1826676", "isize": "8838699", "md5sum": "4dab9ac88d6d68c2b2bb3364c382e101", "sha256sum": "5688a6b8ade9f417fae2f8d66c943f0e5828e762bc5b33f43a5ad7e4db557cef", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmaY8f0ACgkQdxk/FSvb5qam7RAAvGiiMV+zTni80F9fD5MICx91LQIX4JNQUI/5VaHsqyEgeQ800Coo8hSKLyYvdVnZNjlQliWaFwriVncsx4p6pmwoZHOZkSAmPD3aT0ZJpQCX1JnD67m9+JNoK0ydvD43+NKvcdedoie06wOtl656l/XU6qcvBSeViCkJRVMBCpMysRA87+uKZOZB5cQnYbyOsvj/QZfV/c5JWxR0pq2IiuaWzg9Gan1okuNCKCoK58JstHUEZVth8jRqzFOICX6YgcF8dUeU3e4lI+ZsL7DuFUHYoG02ISjdd8AOwRP64ilOzt9TCcOCL4EXJk1HRRslrHLT1WOei6EGc+9AgubmqaOQgIbv2viVthgw6YMj0QHLSnvsWhqcI9rrC9EP5NOLMGQnhyEee00t0kkUQMKwVU9bb6BKsErRMvRVqCri/RVTn6Sn0pC7A+QMlaxWUscWVRhrsofVx+vZVFBEeEEZDU9UYvwYzkDGRBXQR3HWJ6l5KnZsOa4x+PDMEJmOQBexpRdBx9ejyVifBtE2u/AJBHAN2jsdYEZwT6UkT/xHWZT7I0VbKi9hxTkH+D3LSb2XibpHBD9EG9lQf0lxZAAyDW3iPVnvkQdxgKQMkMsEDLgmym8HHJEWI6xjQEEkjRe3sW3mgzZEOJi9SJWUk4NeMNwtjSGXRuPl96Kop7rcJzc=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1721299182", "packager": "Arch Linux ARM Build System <builder+n1@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}