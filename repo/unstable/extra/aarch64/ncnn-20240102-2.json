{"filename": "ncnn-20240102-2-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20240102-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "1851072", "isize": "8808108", "md5sum": "92c44d97bdde2d6224092f009fdf255a", "sha256sum": "045688247e952f704dec32349ea71b5434d0009a60067c53222b7f39521c3827", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmX9CF0ACgkQdxk/FSvb5qY5nw/+KQJyO0qGyK4+zisUHJ2gWbSyGfFzcXKqzgHI3IUfBL3n/KXaJm2SL703WmpV1uy6+Mw5hq9sq9JGGATLkqoEpA/6KDWgKdBkxwur3m+/MmXLK/fFGfScWC1p9oReY37tkU6Nw4xRRCteDszZtngdwPmD9/HslqX6QyDalHpMxXM4BtmwM/7Jt4xUKykrd+sVi1+w6npBLqI+gjPnmnoaepSsZxzLKmqnKOeuNwZ87n1pBGfGQR0jpVCnkE/fMy3gs6yqiuqX12qXmfT1dhU8mHtTW5ng90HsKEtXwqYMKXmrj395A7R7nQUiHcKgze8y+TmoE3xb/NKUEHAEj3X30wMXuYUvqxquzDKbgKMfDEuqrDIdeLpZlh7U1q7kRKFC1s8iONYxLiBcI1jTnproJz31k5nhNzf285cqpYJZyumSZqeyN4jrq/eJBUMX+VOsjULTh5LreGJ5XlkSaTcaAyC6ejV0RkYlXBMvgWSV1vNuVmF4pPzqC6WuHtmf5pvotTJNqX3mUGGzarqppJpkGiRI0WPncM2OdFS96BhYrzXYmDjnplQkpAaQ4g/a0bS9SR1yVT8N1D+/EjQrDnthdQwdJA4LKPXyKVFMJSR5ICKuIQLYrHBc+Kk5pFyNxPNbyrdrTeoofSDwLrC4uBVDOtTONJjxMFbCHCWW2otRWSQ=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1711081326", "packager": "Arch Linux ARM Build System <builder+n1@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}