{"filename": "ncnn-20230816-2-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20230816-2", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2501920", "isize": "11410002", "md5sum": "b9bd671f10f7e7c521e9b9d1d886f623", "sha256sum": "d35fe561006cb66cf9dd09fa9489c9f4c017893c36f8a0eba113541144dd86a7", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmULrIMACgkQdxk/FSvb5qbEig//WY7tT91aCf94yB8opB0Sm5vR03GHzPXdZx8VeAKt9MCLNqeW8GcNd3v1pNh75mfB6Ntg3ZCOlfi60zrt/zFNyhSq5Q0lel+wd5S7rBXt2luWQIduCYA5sQgJRCZN/lcSMAggV109YlBKx3f3yr4v8B2n6CnUIt1N+0bSkPTe/Xs09Pfkk02Nwsa11aWDxmFNhq+0yQp85zEw0td9QNIhVQvMFGiVaPaTrchIgJJ/hk6c3ehpUQ+LgPPItXsoJobh7d8nSw7vLxXVnHSLy09foRBYG8bZ+qNrenMJesX40nYitMNO5Jd+fy/y8YKCgfk/FN/6+5ybCBhQ51z6AO0CywxhlndqbXMpp24R1dNel93WULyVHgTg0p7uRd0gdMKbai56QHyEILus3S+vS6G7WC4KYydTQbtaZ/uKBELhHcTc8TzxyOdCyPzunEjfXTbkRFs65GBVjDec5RZS44cDFDnDHeCE8DeEv20jBuWqudf1xmo4+ISURU9TcYWiE1Yy4dNBiDxwuN4N6A+wGiEFVGXrIiLO36ouBcCOgsZQSvffC4WcincTlrlZhyLMOAEzcXga4WwhCt/7asrnQ2maejDmipbGrjlSXU815LVCsf5RSuoMwZUYPwRz2s4JV30SMYA4Tqy/e03Wc++3kP1T+chI4H7v27Xk+NStnK9015c=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1695263732", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_unstable", "ncnn_aarch64_unstable"]}