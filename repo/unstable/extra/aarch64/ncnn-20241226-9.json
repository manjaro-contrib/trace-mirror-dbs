{"filename": "ncnn-20241226-9-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20241226-9", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "1929776", "isize": "8975086", "md5sum": "035e2c2bcb2a6bff7efd048e1a7b8770", "sha256sum": "71327346c41c3f9feb0e46a63d28c90f1b91eda45a2f768ab5694229a50a0e96", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmhOG28ACgkQdxk/FSvb5qaAYA/9Hu99YxgXnnWp/ckK7ASXJ4mJDk0pPu8FT+89ucfTyil+ZdbvkSK3fF+GOLglTZXynTmAd1As1ty0pxnUrLHF2lqZ0xNULKQqCZgsu3Ene7RZZGGcFmfVqwGK7MASK1r9Phgfu4HC6wklFD1nCPJgA/cAHIN9w1lButmpygDWwD3u/C9ju6esFJHTzNyFf2Z2gKwfEZI+QYKebzVjN+Y2a/h8cNzFtFdEfSECWCt1ukWLfqDM/vb69quvMhmhR4TpYqFkrvvklyvYAteaoTFdSyibMGactjzR7ZlPwk1PtJYY1AUfIussSUQBpeDqdaI/s2QOWWWwXYxYXOWeasQd1KjZLhR1nk+iQufAsDoSdsckcDehFX/hLC3S1pNK6hEkMqD4FXfFPiIhXJmvkbY81njxz+kVEYm2eurkxZSEbp7zQ8tuYi7YQvoL9XjXHlEaSn5PVXcMmkPTRUm2H7PYaAeKtiXfrlNzKM0O6andHsBQ1aF2xWko7iUwhkB4ECS0mVNs8LiROrf+hcCap06q0BlCCe0Hpe+dAUcYe7Zd28Jyur94EGR6AbiN+VGMGHa588U124ImDkyLcXLN6fgPm3TBMCF9zUVE57IIfLTB3GX8sv9fKGI3lRK3KikPPHGijmIgZ1D+ZtTn2mX1QYTafMBltbiAAbH39zm8CLkohf4=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1749948982", "packager": "Arch Linux ARM Build System <builder+n1@archlinuxarm.org>", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["git", "cmake", "glslang", "ninja", "protobuf", "vulkan-headers"]}