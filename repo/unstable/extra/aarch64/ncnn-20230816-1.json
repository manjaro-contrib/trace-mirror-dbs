{"filename": "ncnn-20230816-1-aarch64.pkg.tar.xz", "name": "ncnn", "base": "ncnn", "version": "20230816-1", "desc": "High-performance neural network inference framework optimized for the mobile platform", "csize": "2496848", "isize": "11393554", "md5sum": "39cb536834a752163cb403cfb0069e91", "sha256sum": "7f9430b88c925aae703027eed8466cb71443971a957f85323870969f8b509941", "pgpsig": "iQIzBAABCAAdFiEEaLNTfzmjE7PldNBndxk/FSvb5qYFAmTvs3QACgkQdxk/FSvb5qa7BhAAxnfVU4IOTXlct3LFLGyMnV9GA6OQQEu0nCCA+BT7udTOV26U4zRRSR4/tkPB1wOUvmqypOuXE7db4wa56ZbQfShiQgnk8YS73RdHbGLulruCL2l/n+Bin/nG3DFmZVyLx5HRmmcFNsTWefLLMNiHErVRa/NR48XQfF3XE8LjnEh52HVxisydWEKEwPQSoecJT8IVUdbqVTci9ruJnruyatZI5YxUqxmyEx6DVLCOLb49+PQdPBmr/BPFxNIpGmN4mRp4/EgoRQVoQ1hZ0TwpxmiuMrustM061ubR6TMCTjnOtzCh6jurYpr5R6W+w28c7Rd8SZ1jFSqvtPc0YesFkLeqM8jUzYhq1NKDw3rXkgOSiDF14Hjl3zR2Y6Vps1jOxbVQD7S3bUcMnfVtV5gXr6j9Pe+8b+fZBLFDUBxdgYoCcqcRSrp26pGyuBuH/TYXPjDXSrddZFEV1SVrrlQ62u+5Lt1ZrPiqrrTN7B88O0jIv7/IPKcYnnkS5iHl2vrgjhgN6QdTvEK1PRNbu144G/bfsrg6/IWEKspPm0fmztQpql3vyytMhqPutRbMyFNfxhBl1ZfvdVocKbwu/OmtVreP7fYaGbEiLOQYyD7wEStJqwAgI8DjMFgiEIL1WsShEfa0pxdzgjboRLbuVVOI+xdaiSLHva8gT8anlVyNltI=", "url": "https://github.com/Tencent/ncnn", "license": "BSD", "arch": "aarch64", "builddate": "1693430504", "packager": "Arch Linux ARM Build System <builder+seattle@archlinuxarm.org>", "conflicts": "ncnn-git", "depends": ["vulkan-icd-loader"], "optdepends": "protobuf: for onnx2ncnn", "makedepends": ["cmake", "glslang", "ninja", "protobuf", "vulkan-headers"], "tokens": ["ncnn", "ncnn_aarch64", "ncnn_unstable", "ncnn_aarch64_unstable"]}